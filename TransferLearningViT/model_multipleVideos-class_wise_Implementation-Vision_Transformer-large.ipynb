{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a3c64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from itertools import count\n",
    "import natsort\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ad8105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25fd105f130>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import glob\n",
    "import numpy\n",
    "import random\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8edee91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 11.3\n",
      "ID of current CUDA device: 0\n",
      "Name of current CUDA device: NVIDIA GeForce RTX 2070 Super\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
    "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848161dc",
   "metadata": {},
   "source": [
    "# Building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3d526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurgicalDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=False):\n",
    "        super(SurgicalDataset, self).__init__()\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels    #.astype(dtype='int')\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        \n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad62ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(model_name):\n",
    "\n",
    "    if model_name == 'alexnet':\n",
    "        transform = A.Compose([\n",
    "            A.Resize(227, 227),\n",
    "            A.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif model_name == 'effinet':\n",
    "        transform = A.Compose([\n",
    "            A.Resize(224, 224),\n",
    "            A.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "    elif model_name == 'TransferViT':\n",
    "        \n",
    "        transform = A.Compose([\n",
    "            A.Resize(224, 224),\n",
    "            A.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e030c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_image_paths1) 215057\n",
      "len(df2) 215057\n",
      "train_labels 172045\n",
      "train_image_paths 172045\n",
      "label distribution in the training data [  243  8681 22901 41140   952 22305   666 10930   896  2308 44928 12987\n",
      "  1789  1246    73]\n"
     ]
    }
   ],
   "source": [
    "# Preparing the datasets\n",
    "# Get images\n",
    "train_image_paths = []\n",
    "train_data_path = r\"C:\\Users\\panji\\EECS6691_Advanced_DL\\Assignment2\\training_data_images\"\n",
    "train_image_paths.append(glob.glob(train_data_path + '/*'))\n",
    "# unpack the listed list\n",
    "train_image_paths1 = [item for sublist in train_image_paths for item in sublist]\n",
    "train_image_paths1 = natsort.natsorted(train_image_paths1)\n",
    "print('len(train_image_paths1)', len(train_image_paths1))\n",
    "\n",
    "# Get labels\n",
    "df = pd.read_csv(\"Processed_data.csv\")\n",
    "df1 = df.loc[:,\"Phases\"].to_numpy()\n",
    "df2 = df1.tolist()\n",
    "print('len(df2)', len(df2))\n",
    "\n",
    "# Preparing the datasets (images and labels)\n",
    "dataset_train = pd.DataFrame(\n",
    "    {'Link': train_image_paths1,\n",
    "     'Label': df2,\n",
    "    })\n",
    "dataset_train1 = dataset_train.sample(frac=1, random_state=1)\n",
    "train_image_paths = dataset_train1.loc[:,\"Link\"].to_numpy().tolist()\n",
    "labels = dataset_train1.loc[:,\"Label\"].to_numpy().tolist()\n",
    "\n",
    "# manually split the dataset\n",
    "train_image_paths, valid_image_paths = train_image_paths[:int(0.8*len(train_image_paths))], train_image_paths[int(0.8*len(train_image_paths)):]  \n",
    "train_labels, valid_labels = labels[:int(0.8*len(labels))], labels[int(0.8*len(labels)):] \n",
    "print('train_labels', len(train_labels))\n",
    "print('train_image_paths', len(train_image_paths))\n",
    "print('label distribution in the training data', np.bincount(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69671af2",
   "metadata": {},
   "source": [
    "# Weighted Data Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa1ba5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df2) 215057\n",
      "{0: 243, 1: 8681, 2: 22901, 3: 41140, 4: 952, 5: 22305, 6: 666, 7: 10930, 8: 896, 9: 2308, 10: 44928, 11: 12987, 12: 1789, 13: 1246, 14: 73}\n",
      "172045\n",
      "15\n",
      "172045\n",
      "172045\n"
     ]
    }
   ],
   "source": [
    "# from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# Get labels\n",
    "df = pd.read_csv(\"Processed_data.csv\")\n",
    "df1 = df.loc[:,\"Phases\"].to_numpy()\n",
    "df2 = df1.tolist()\n",
    "print('len(df2)', len(df2))\n",
    "\n",
    "# Preparing the datasets (images and labels)\n",
    "dataset_train = pd.DataFrame(\n",
    "    {'Link': train_image_paths1,\n",
    "     'Label': df2,\n",
    "    })\n",
    "dataset_train1 = dataset_train.sample(frac=1, random_state=1)\n",
    "train_image_paths = dataset_train1.loc[:,\"Link\"].to_numpy().tolist()\n",
    "labels = dataset_train1.loc[:,\"Label\"].to_numpy().tolist()\n",
    "\n",
    "summary = {i:0 for i in range(15)}\n",
    "num_classes = 15\n",
    "total_samples = 0\n",
    "for i in train_labels:\n",
    "    total_samples += 1\n",
    "    summary[i] += 1\n",
    "print(summary)\n",
    "print(total_samples)\n",
    "\n",
    "class_weights = [total_samples/summary[i] for i in range(num_classes)]\n",
    "weights = [class_weights[train_labels[i]] for i in range(total_samples)]\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(weights), len(weights))\n",
    "print(len(class_weights))\n",
    "print(len(weights))\n",
    "print(len(list(sampler)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c62de6",
   "metadata": {},
   "source": [
    "# Building the classifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b4e3a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier():\n",
    "\n",
    "    def __init__(self, name, model, dataloaders, parameter, use_cuda=False):\n",
    "        \n",
    "        '''\n",
    "        @name: Experiment name. Will define stored results etc. \n",
    "        @model: Any models\n",
    "        @dataloaders: Dictionary with keys train, val and test and corresponding dataloaders\n",
    "        @class_names: list of classes, where the idx of class name corresponds to the label used for it in the data\n",
    "        @use_cuda: whether or not to use cuda\n",
    "        '''\n",
    "       \n",
    "        self.name = name\n",
    "        if use_cuda and not torch.cuda.is_available():\n",
    "            raise Exception(\"Asked for CUDA but GPU not found\")\n",
    "            \n",
    "        self.use_cuda = use_cuda\n",
    "        self.epoch = parameter['epochs']\n",
    "        self.lr = parameter['lr']\n",
    "        self.batch_size = parameter['batch_size']\n",
    "        \n",
    "        self.model = model.to('cuda' if use_cuda else 'cpu') # model.to('cpu')\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.train_loader, self.valid_loader = self.get_dataloaders(dataloaders['train_image_paths'], \n",
    "                                                                    dataloaders['train_labels'], \n",
    "                                                                    dataloaders['valid_image_paths'], \n",
    "                                                                    dataloaders['valid_labels'], \n",
    "                                                                    train_transforms=dataloaders['transforms'], \n",
    "                                                                    batch_size = self.batch_size,\n",
    "                                                                    shuffle=parameter['shuffle'],\n",
    "                                                                   sampler = dataloaders['sampler'])\n",
    "        self.class_names = parameter['class_names']\n",
    "        \n",
    "        self.activations_path = os.path.join('activations', self.name)\n",
    "        self.kernel_path = os.path.join('kernel_viz', self.name)\n",
    "        save_path = os.path.join(os.getcwd(), 'models', self.name)\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        if not os.path.exists(self.activations_path):\n",
    "            os.makedirs(self.activations_path)\n",
    "\n",
    "        if not os.path.exists(self.kernel_path):\n",
    "            os.makedirs(self.kernel_path)\n",
    "            \n",
    "        self.save_path = save_path\n",
    "\n",
    "    def train(self, save=True):\n",
    "        '''\n",
    "        @epochs: number of epochs to train\n",
    "        @save: whether or not to save the checkpoints\n",
    "        '''\n",
    "        best_val_accuracy = - math.inf\n",
    "        \n",
    "        for epoch in range(self.epoch):  # loop over the dataset multiple times\n",
    "            self.model.train()\n",
    "            t = time.time()\n",
    "            running_loss = 0.0\n",
    "            train_acc = 0\n",
    "            val_accuracy = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            count = 0\n",
    "            loop = tqdm.tqdm(self.train_loader, total = len(self.train_loader), leave = True)\n",
    "            \n",
    "            for img, label in loop:\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = img.to(device), label.to(device) #img.to(device), label.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = self.model(inputs)\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                total += labels.shape[0]\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                \n",
    "                count += 1\n",
    "                if count % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                    print(f'[{epoch + 1}, {count + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                    running_loss = 0.0\n",
    "                    \n",
    "            train_acc = 100 * correct / total\n",
    "            print(f'Epoch:', epoch + 1, f'Training Epoch Accuracy:{train_acc}')\n",
    "            \n",
    "            # evaluate the validation dataset\n",
    "            self.model.eval()\n",
    "            correct_pred = {classname: 0 for classname in self.class_names}\n",
    "            total_pred = {classname: 0 for classname in self.class_names}\n",
    "\n",
    "            # again no gradients needed\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data in self.valid_loader:\n",
    "                    images, labels = data[0].to(device), data[1].to(device) #data[0], data[1]\n",
    "                    outputs = self.model(images)\n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    # collect the correct predictions for each class\n",
    "                    total += labels.shape[0]\n",
    "                    correct += (predictions == labels).sum().item()\n",
    "\n",
    "                    for label, prediction in zip(labels, predictions):\n",
    "                        if label == prediction:\n",
    "                            correct_pred[classes[label]] += 1\n",
    "                        total_pred[classes[label]] += 1\n",
    "\n",
    "            val_accuracy = 100 * correct / total\n",
    "            print(f'Epoch:', epoch + 1, f'Validation Epoch Accuracy:{val_accuracy}')\n",
    "                        \n",
    "            # print the summary for each class\n",
    "            print('Epoch:', epoch + 1, 'Correct predictions', correct_pred)\n",
    "            print('Epoch:', epoch + 1, 'Total predictions', total_pred)\n",
    "            print('Epoch:', epoch + 1, 'Correct predictions', correct_pred)\n",
    "            print('Epoch:', epoch + 1, 'Total predictions', total_pred)\n",
    "            \n",
    "            # inspect the time taken to train one epoch\n",
    "            d = time.time()-t\n",
    "            print('Fininsh Trainig Epoch', epoch, '!', 'Time used:', d)\n",
    "            \n",
    "            if save:\n",
    "                torch.save(self.model.state_dict(), os.path.join(self.save_path, f'epoch_{epoch}.pt'))\n",
    "                if val_accuracy > best_val_accuracy:\n",
    "                    torch.save(self.model.state_dict(), os.path.join(self.save_path, 'best.pt'))\n",
    "                    best_val_accuracy = val_accuracy\n",
    "\n",
    "        print('Done training!')                       \n",
    "\n",
    "    \n",
    "    def evaluate(self):\n",
    "        # for evaluating the test dataset if there were any.\n",
    "        try:\n",
    "            assert os.path.exists(os.path.join(self.save_path, 'best.pt'))\n",
    "            \n",
    "        except:\n",
    "            print('Please train first')\n",
    "            return\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(os.path.join(self.save_path, 'best.pt')))\n",
    "        self.model.eval()\n",
    "        \n",
    "        \n",
    "    def get_dataloaders(self, train_image_paths, train_labels, valid_image_paths, valid_labels, train_transforms=False, batch_size=32, shuffle=True, sampler = None):\n",
    "        train_dataset = SurgicalDataset(train_image_paths,train_labels, train_transforms)\n",
    "        val_dataset = SurgicalDataset(valid_image_paths,valid_labels, train_transforms)\n",
    "        train_loader = DataLoader(train_dataset, batch_size, shuffle, sampler)\n",
    "        valid_loader = DataLoader(val_dataset, batch_size, shuffle = True)\n",
    "        \n",
    "        return train_loader, valid_loader\n",
    "    \n",
    "\n",
    "    def grad_cam_on_input(self, img):\n",
    "        \n",
    "        try:\n",
    "            assert os.path.exists(os.path.join(self.save_path, 'best.pt'))\n",
    "\n",
    "        except:\n",
    "            print('It appears you are testing the model without training. Please train first')\n",
    "            return\n",
    "\n",
    "        self.model.load_state_dict(torch.load(os.path.join(self.save_path, 'best.pt')))\n",
    "\n",
    "\n",
    "        self.model.eval()\n",
    "        img = img.to('cuda' if self.use_cuda else 'cpu')\n",
    "\n",
    "\n",
    "        out = self.model(img)\n",
    "\n",
    "        _, pred = torch.max(out, 1)\n",
    "\n",
    "        predicted_class = self.class_names[int(pred)]\n",
    "        print(f'Predicted class was {predicted_class}')\n",
    "\n",
    "        out[:, pred].backward()\n",
    "        gradients = self.model.get_gradient_activations()\n",
    "\n",
    "        print('Gradients shape: ', f'{gradients.shape}')\n",
    "\n",
    "        mean_gradients = torch.mean(gradients, [0, 2, 3]).cpu()\n",
    "        activations = self.model.get_final_conv_layer(img).detach().cpu()\n",
    "\n",
    "        print('Activations shape: ', f'{activations.shape}')\n",
    "\n",
    "        for idx in range(activations.shape[1]):\n",
    "            activations[:, idx, :, :] *= mean_gradients[idx]\n",
    "\n",
    "        final_heatmap = np.maximum(torch.mean(activations, dim=1).squeeze(), 0)\n",
    "\n",
    "        final_heatmap /= torch.max(final_heatmap)\n",
    "\n",
    "        return final_heatmap\n",
    "\n",
    "    def trained_kernel_viz(self):\n",
    "        \n",
    "        all_layers = [0, 3]\n",
    "        all_filters = []\n",
    "        for layer in all_layers:\n",
    "\n",
    "            filters = self.model.conv_model[layer].weight\n",
    "            all_filters.append(filters.detach().cpu().clone()[:8, :8, :, :])\n",
    "\n",
    "        for filter_idx in range(len(all_filters)):\n",
    "\n",
    "            filter = all_filters[filter_idx]\n",
    "            print(filter.shape)\n",
    "            filter = filter.contiguous().view(-1, 1, filter.shape[2], filter.shape[3])\n",
    "            image = show_img(make_grid(filter))\n",
    "            image = 255 * image\n",
    "            cv2.imwrite(os.path.join(self.kernel_path, f'filter_layer{all_layers[filter_idx]}.jpg'), image)\n",
    "    \n",
    "\n",
    "    def activations_on_input(self, img):\n",
    "        \n",
    "        img = img.to('cuda' if self.use_cuda else 'cpu')\n",
    "\n",
    "        all_layers = [0,3,6,8,10]\n",
    "        all_viz = []\n",
    "        \n",
    "        # looking at the outputs of the relu\n",
    "        for each in all_layers:\n",
    "\n",
    "            current_model = self.model.conv_model[:each+1]\n",
    "            current_out = current_model(img)\n",
    "            all_viz.append(current_out.detach().cpu().clone()[:, :64, :, :])\n",
    "\n",
    "        for viz_idx in range(len(all_viz)):\n",
    "\n",
    "            viz = all_viz[viz_idx]\n",
    "            viz = viz.view(-1, 1, viz.shape[2], viz.shape[3])\n",
    "            image = show_img(make_grid(viz))\n",
    "            image = 255 * image\n",
    "            cv2.imwrite(os.path.join(self.activations_path, f'sample_layer{all_layers[viz_idx]}.jpg'), image)    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f48099",
   "metadata": {},
   "source": [
    "# Build and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f03a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "example_model =  models.vit_l_32(pretrained=True) #vit_b_32 = models.vit_b_32(pretrained=True)\n",
    "count_parameters(example_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18d59f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_model = models.vit_l_32(pretrained=True)\n",
    "# count_parameters(example_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c8bc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vit_l_16 = models.vit_l_16(pretrained=True)\n",
    "# count_parameters(vit_l_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b004fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------+------------+\n",
      "|                            Modules                             | Parameters |\n",
      "+----------------------------------------------------------------+------------+\n",
      "|                          class_token                           |    1024    |\n",
      "|                        conv_proj.weight                        |  3145728   |\n",
      "|                         conv_proj.bias                         |    1024    |\n",
      "|                     encoder.pos_embedding                      |   51200    |\n",
      "|           encoder.layers.encoder_layer_0.ln_1.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_0.ln_1.bias            |    1024    |\n",
      "|  encoder.layers.encoder_layer_0.self_attention.in_proj_weight  |  3145728   |\n",
      "|   encoder.layers.encoder_layer_0.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_0.self_attention.out_proj.weight  |  1048576   |\n",
      "|  encoder.layers.encoder_layer_0.self_attention.out_proj.bias   |    1024    |\n",
      "|           encoder.layers.encoder_layer_0.ln_2.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_0.ln_2.bias            |    1024    |\n",
      "|       encoder.layers.encoder_layer_0.mlp.linear_1.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_0.mlp.linear_1.bias        |    4096    |\n",
      "|       encoder.layers.encoder_layer_0.mlp.linear_2.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_0.mlp.linear_2.bias        |    1024    |\n",
      "|           encoder.layers.encoder_layer_1.ln_1.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_1.ln_1.bias            |    1024    |\n",
      "|  encoder.layers.encoder_layer_1.self_attention.in_proj_weight  |  3145728   |\n",
      "|   encoder.layers.encoder_layer_1.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_1.self_attention.out_proj.weight  |  1048576   |\n",
      "|  encoder.layers.encoder_layer_1.self_attention.out_proj.bias   |    1024    |\n",
      "|           encoder.layers.encoder_layer_1.ln_2.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_1.ln_2.bias            |    1024    |\n",
      "|       encoder.layers.encoder_layer_1.mlp.linear_1.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_1.mlp.linear_1.bias        |    4096    |\n",
      "|       encoder.layers.encoder_layer_1.mlp.linear_2.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_1.mlp.linear_2.bias        |    1024    |\n",
      "|           encoder.layers.encoder_layer_2.ln_1.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_2.ln_1.bias            |    1024    |\n",
      "|  encoder.layers.encoder_layer_2.self_attention.in_proj_weight  |  3145728   |\n",
      "|   encoder.layers.encoder_layer_2.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_2.self_attention.out_proj.weight  |  1048576   |\n",
      "|  encoder.layers.encoder_layer_2.self_attention.out_proj.bias   |    1024    |\n",
      "|           encoder.layers.encoder_layer_2.ln_2.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_2.ln_2.bias            |    1024    |\n",
      "|       encoder.layers.encoder_layer_2.mlp.linear_1.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_2.mlp.linear_1.bias        |    4096    |\n",
      "|       encoder.layers.encoder_layer_2.mlp.linear_2.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_2.mlp.linear_2.bias        |    1024    |\n",
      "|           encoder.layers.encoder_layer_3.ln_1.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_3.ln_1.bias            |    1024    |\n",
      "|  encoder.layers.encoder_layer_3.self_attention.in_proj_weight  |  3145728   |\n",
      "|   encoder.layers.encoder_layer_3.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_3.self_attention.out_proj.weight  |  1048576   |\n",
      "|  encoder.layers.encoder_layer_3.self_attention.out_proj.bias   |    1024    |\n",
      "|           encoder.layers.encoder_layer_3.ln_2.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_3.ln_2.bias            |    1024    |\n",
      "|       encoder.layers.encoder_layer_3.mlp.linear_1.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_3.mlp.linear_1.bias        |    4096    |\n",
      "|       encoder.layers.encoder_layer_3.mlp.linear_2.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_3.mlp.linear_2.bias        |    1024    |\n",
      "|           encoder.layers.encoder_layer_4.ln_1.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_4.ln_1.bias            |    1024    |\n",
      "|  encoder.layers.encoder_layer_4.self_attention.in_proj_weight  |  3145728   |\n",
      "|   encoder.layers.encoder_layer_4.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_4.self_attention.out_proj.weight  |  1048576   |\n",
      "|  encoder.layers.encoder_layer_4.self_attention.out_proj.bias   |    1024    |\n",
      "|           encoder.layers.encoder_layer_4.ln_2.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_4.ln_2.bias            |    1024    |\n",
      "|       encoder.layers.encoder_layer_4.mlp.linear_1.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_4.mlp.linear_1.bias        |    4096    |\n",
      "|       encoder.layers.encoder_layer_4.mlp.linear_2.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_4.mlp.linear_2.bias        |    1024    |\n",
      "|           encoder.layers.encoder_layer_5.ln_1.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_5.ln_1.bias            |    1024    |\n",
      "|  encoder.layers.encoder_layer_5.self_attention.in_proj_weight  |  3145728   |\n",
      "|   encoder.layers.encoder_layer_5.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_5.self_attention.out_proj.weight  |  1048576   |\n",
      "|  encoder.layers.encoder_layer_5.self_attention.out_proj.bias   |    1024    |\n",
      "|           encoder.layers.encoder_layer_5.ln_2.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_5.ln_2.bias            |    1024    |\n",
      "|       encoder.layers.encoder_layer_5.mlp.linear_1.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_5.mlp.linear_1.bias        |    4096    |\n",
      "|       encoder.layers.encoder_layer_5.mlp.linear_2.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_5.mlp.linear_2.bias        |    1024    |\n",
      "|           encoder.layers.encoder_layer_6.ln_1.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_6.ln_1.bias            |    1024    |\n",
      "|  encoder.layers.encoder_layer_6.self_attention.in_proj_weight  |  3145728   |\n",
      "|   encoder.layers.encoder_layer_6.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_6.self_attention.out_proj.weight  |  1048576   |\n",
      "|  encoder.layers.encoder_layer_6.self_attention.out_proj.bias   |    1024    |\n",
      "|           encoder.layers.encoder_layer_6.ln_2.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_6.ln_2.bias            |    1024    |\n",
      "|       encoder.layers.encoder_layer_6.mlp.linear_1.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_6.mlp.linear_1.bias        |    4096    |\n",
      "|       encoder.layers.encoder_layer_6.mlp.linear_2.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_6.mlp.linear_2.bias        |    1024    |\n",
      "|           encoder.layers.encoder_layer_7.ln_1.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_7.ln_1.bias            |    1024    |\n",
      "|  encoder.layers.encoder_layer_7.self_attention.in_proj_weight  |  3145728   |\n",
      "|   encoder.layers.encoder_layer_7.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_7.self_attention.out_proj.weight  |  1048576   |\n",
      "|  encoder.layers.encoder_layer_7.self_attention.out_proj.bias   |    1024    |\n",
      "|           encoder.layers.encoder_layer_7.ln_2.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_7.ln_2.bias            |    1024    |\n",
      "|       encoder.layers.encoder_layer_7.mlp.linear_1.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_7.mlp.linear_1.bias        |    4096    |\n",
      "|       encoder.layers.encoder_layer_7.mlp.linear_2.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_7.mlp.linear_2.bias        |    1024    |\n",
      "|           encoder.layers.encoder_layer_8.ln_1.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_8.ln_1.bias            |    1024    |\n",
      "|  encoder.layers.encoder_layer_8.self_attention.in_proj_weight  |  3145728   |\n",
      "|   encoder.layers.encoder_layer_8.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_8.self_attention.out_proj.weight  |  1048576   |\n",
      "|  encoder.layers.encoder_layer_8.self_attention.out_proj.bias   |    1024    |\n",
      "|           encoder.layers.encoder_layer_8.ln_2.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_8.ln_2.bias            |    1024    |\n",
      "|       encoder.layers.encoder_layer_8.mlp.linear_1.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_8.mlp.linear_1.bias        |    4096    |\n",
      "|       encoder.layers.encoder_layer_8.mlp.linear_2.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_8.mlp.linear_2.bias        |    1024    |\n",
      "|           encoder.layers.encoder_layer_9.ln_1.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_9.ln_1.bias            |    1024    |\n",
      "|  encoder.layers.encoder_layer_9.self_attention.in_proj_weight  |  3145728   |\n",
      "|   encoder.layers.encoder_layer_9.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_9.self_attention.out_proj.weight  |  1048576   |\n",
      "|  encoder.layers.encoder_layer_9.self_attention.out_proj.bias   |    1024    |\n",
      "|           encoder.layers.encoder_layer_9.ln_2.weight           |    1024    |\n",
      "|            encoder.layers.encoder_layer_9.ln_2.bias            |    1024    |\n",
      "|       encoder.layers.encoder_layer_9.mlp.linear_1.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_9.mlp.linear_1.bias        |    4096    |\n",
      "|       encoder.layers.encoder_layer_9.mlp.linear_2.weight       |  4194304   |\n",
      "|        encoder.layers.encoder_layer_9.mlp.linear_2.bias        |    1024    |\n",
      "|          encoder.layers.encoder_layer_10.ln_1.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_10.ln_1.bias            |    1024    |\n",
      "| encoder.layers.encoder_layer_10.self_attention.in_proj_weight  |  3145728   |\n",
      "|  encoder.layers.encoder_layer_10.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_10.self_attention.out_proj.weight |  1048576   |\n",
      "|  encoder.layers.encoder_layer_10.self_attention.out_proj.bias  |    1024    |\n",
      "|          encoder.layers.encoder_layer_10.ln_2.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_10.ln_2.bias            |    1024    |\n",
      "|      encoder.layers.encoder_layer_10.mlp.linear_1.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_10.mlp.linear_1.bias        |    4096    |\n",
      "|      encoder.layers.encoder_layer_10.mlp.linear_2.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_10.mlp.linear_2.bias        |    1024    |\n",
      "|          encoder.layers.encoder_layer_11.ln_1.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_11.ln_1.bias            |    1024    |\n",
      "| encoder.layers.encoder_layer_11.self_attention.in_proj_weight  |  3145728   |\n",
      "|  encoder.layers.encoder_layer_11.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_11.self_attention.out_proj.weight |  1048576   |\n",
      "|  encoder.layers.encoder_layer_11.self_attention.out_proj.bias  |    1024    |\n",
      "|          encoder.layers.encoder_layer_11.ln_2.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_11.ln_2.bias            |    1024    |\n",
      "|      encoder.layers.encoder_layer_11.mlp.linear_1.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_11.mlp.linear_1.bias        |    4096    |\n",
      "|      encoder.layers.encoder_layer_11.mlp.linear_2.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_11.mlp.linear_2.bias        |    1024    |\n",
      "|          encoder.layers.encoder_layer_12.ln_1.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_12.ln_1.bias            |    1024    |\n",
      "| encoder.layers.encoder_layer_12.self_attention.in_proj_weight  |  3145728   |\n",
      "|  encoder.layers.encoder_layer_12.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_12.self_attention.out_proj.weight |  1048576   |\n",
      "|  encoder.layers.encoder_layer_12.self_attention.out_proj.bias  |    1024    |\n",
      "|          encoder.layers.encoder_layer_12.ln_2.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_12.ln_2.bias            |    1024    |\n",
      "|      encoder.layers.encoder_layer_12.mlp.linear_1.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_12.mlp.linear_1.bias        |    4096    |\n",
      "|      encoder.layers.encoder_layer_12.mlp.linear_2.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_12.mlp.linear_2.bias        |    1024    |\n",
      "|          encoder.layers.encoder_layer_13.ln_1.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_13.ln_1.bias            |    1024    |\n",
      "| encoder.layers.encoder_layer_13.self_attention.in_proj_weight  |  3145728   |\n",
      "|  encoder.layers.encoder_layer_13.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_13.self_attention.out_proj.weight |  1048576   |\n",
      "|  encoder.layers.encoder_layer_13.self_attention.out_proj.bias  |    1024    |\n",
      "|          encoder.layers.encoder_layer_13.ln_2.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_13.ln_2.bias            |    1024    |\n",
      "|      encoder.layers.encoder_layer_13.mlp.linear_1.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_13.mlp.linear_1.bias        |    4096    |\n",
      "|      encoder.layers.encoder_layer_13.mlp.linear_2.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_13.mlp.linear_2.bias        |    1024    |\n",
      "|          encoder.layers.encoder_layer_14.ln_1.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_14.ln_1.bias            |    1024    |\n",
      "| encoder.layers.encoder_layer_14.self_attention.in_proj_weight  |  3145728   |\n",
      "|  encoder.layers.encoder_layer_14.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_14.self_attention.out_proj.weight |  1048576   |\n",
      "|  encoder.layers.encoder_layer_14.self_attention.out_proj.bias  |    1024    |\n",
      "|          encoder.layers.encoder_layer_14.ln_2.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_14.ln_2.bias            |    1024    |\n",
      "|      encoder.layers.encoder_layer_14.mlp.linear_1.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_14.mlp.linear_1.bias        |    4096    |\n",
      "|      encoder.layers.encoder_layer_14.mlp.linear_2.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_14.mlp.linear_2.bias        |    1024    |\n",
      "|          encoder.layers.encoder_layer_15.ln_1.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_15.ln_1.bias            |    1024    |\n",
      "| encoder.layers.encoder_layer_15.self_attention.in_proj_weight  |  3145728   |\n",
      "|  encoder.layers.encoder_layer_15.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_15.self_attention.out_proj.weight |  1048576   |\n",
      "|  encoder.layers.encoder_layer_15.self_attention.out_proj.bias  |    1024    |\n",
      "|          encoder.layers.encoder_layer_15.ln_2.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_15.ln_2.bias            |    1024    |\n",
      "|      encoder.layers.encoder_layer_15.mlp.linear_1.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_15.mlp.linear_1.bias        |    4096    |\n",
      "|      encoder.layers.encoder_layer_15.mlp.linear_2.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_15.mlp.linear_2.bias        |    1024    |\n",
      "|          encoder.layers.encoder_layer_16.ln_1.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_16.ln_1.bias            |    1024    |\n",
      "| encoder.layers.encoder_layer_16.self_attention.in_proj_weight  |  3145728   |\n",
      "|  encoder.layers.encoder_layer_16.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_16.self_attention.out_proj.weight |  1048576   |\n",
      "|  encoder.layers.encoder_layer_16.self_attention.out_proj.bias  |    1024    |\n",
      "|          encoder.layers.encoder_layer_16.ln_2.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_16.ln_2.bias            |    1024    |\n",
      "|      encoder.layers.encoder_layer_16.mlp.linear_1.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_16.mlp.linear_1.bias        |    4096    |\n",
      "|      encoder.layers.encoder_layer_16.mlp.linear_2.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_16.mlp.linear_2.bias        |    1024    |\n",
      "|          encoder.layers.encoder_layer_17.ln_1.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_17.ln_1.bias            |    1024    |\n",
      "| encoder.layers.encoder_layer_17.self_attention.in_proj_weight  |  3145728   |\n",
      "|  encoder.layers.encoder_layer_17.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_17.self_attention.out_proj.weight |  1048576   |\n",
      "|  encoder.layers.encoder_layer_17.self_attention.out_proj.bias  |    1024    |\n",
      "|          encoder.layers.encoder_layer_17.ln_2.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_17.ln_2.bias            |    1024    |\n",
      "|      encoder.layers.encoder_layer_17.mlp.linear_1.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_17.mlp.linear_1.bias        |    4096    |\n",
      "|      encoder.layers.encoder_layer_17.mlp.linear_2.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_17.mlp.linear_2.bias        |    1024    |\n",
      "|          encoder.layers.encoder_layer_18.ln_1.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_18.ln_1.bias            |    1024    |\n",
      "| encoder.layers.encoder_layer_18.self_attention.in_proj_weight  |  3145728   |\n",
      "|  encoder.layers.encoder_layer_18.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_18.self_attention.out_proj.weight |  1048576   |\n",
      "|  encoder.layers.encoder_layer_18.self_attention.out_proj.bias  |    1024    |\n",
      "|          encoder.layers.encoder_layer_18.ln_2.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_18.ln_2.bias            |    1024    |\n",
      "|      encoder.layers.encoder_layer_18.mlp.linear_1.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_18.mlp.linear_1.bias        |    4096    |\n",
      "|      encoder.layers.encoder_layer_18.mlp.linear_2.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_18.mlp.linear_2.bias        |    1024    |\n",
      "|          encoder.layers.encoder_layer_19.ln_1.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_19.ln_1.bias            |    1024    |\n",
      "| encoder.layers.encoder_layer_19.self_attention.in_proj_weight  |  3145728   |\n",
      "|  encoder.layers.encoder_layer_19.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_19.self_attention.out_proj.weight |  1048576   |\n",
      "|  encoder.layers.encoder_layer_19.self_attention.out_proj.bias  |    1024    |\n",
      "|          encoder.layers.encoder_layer_19.ln_2.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_19.ln_2.bias            |    1024    |\n",
      "|      encoder.layers.encoder_layer_19.mlp.linear_1.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_19.mlp.linear_1.bias        |    4096    |\n",
      "|      encoder.layers.encoder_layer_19.mlp.linear_2.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_19.mlp.linear_2.bias        |    1024    |\n",
      "|          encoder.layers.encoder_layer_20.ln_1.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_20.ln_1.bias            |    1024    |\n",
      "| encoder.layers.encoder_layer_20.self_attention.in_proj_weight  |  3145728   |\n",
      "|  encoder.layers.encoder_layer_20.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_20.self_attention.out_proj.weight |  1048576   |\n",
      "|  encoder.layers.encoder_layer_20.self_attention.out_proj.bias  |    1024    |\n",
      "|          encoder.layers.encoder_layer_20.ln_2.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_20.ln_2.bias            |    1024    |\n",
      "|      encoder.layers.encoder_layer_20.mlp.linear_1.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_20.mlp.linear_1.bias        |    4096    |\n",
      "|      encoder.layers.encoder_layer_20.mlp.linear_2.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_20.mlp.linear_2.bias        |    1024    |\n",
      "|          encoder.layers.encoder_layer_21.ln_1.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_21.ln_1.bias            |    1024    |\n",
      "| encoder.layers.encoder_layer_21.self_attention.in_proj_weight  |  3145728   |\n",
      "|  encoder.layers.encoder_layer_21.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_21.self_attention.out_proj.weight |  1048576   |\n",
      "|  encoder.layers.encoder_layer_21.self_attention.out_proj.bias  |    1024    |\n",
      "|          encoder.layers.encoder_layer_21.ln_2.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_21.ln_2.bias            |    1024    |\n",
      "|      encoder.layers.encoder_layer_21.mlp.linear_1.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_21.mlp.linear_1.bias        |    4096    |\n",
      "|      encoder.layers.encoder_layer_21.mlp.linear_2.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_21.mlp.linear_2.bias        |    1024    |\n",
      "|          encoder.layers.encoder_layer_22.ln_1.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_22.ln_1.bias            |    1024    |\n",
      "| encoder.layers.encoder_layer_22.self_attention.in_proj_weight  |  3145728   |\n",
      "|  encoder.layers.encoder_layer_22.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_22.self_attention.out_proj.weight |  1048576   |\n",
      "|  encoder.layers.encoder_layer_22.self_attention.out_proj.bias  |    1024    |\n",
      "|          encoder.layers.encoder_layer_22.ln_2.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_22.ln_2.bias            |    1024    |\n",
      "|      encoder.layers.encoder_layer_22.mlp.linear_1.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_22.mlp.linear_1.bias        |    4096    |\n",
      "|      encoder.layers.encoder_layer_22.mlp.linear_2.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_22.mlp.linear_2.bias        |    1024    |\n",
      "|          encoder.layers.encoder_layer_23.ln_1.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_23.ln_1.bias            |    1024    |\n",
      "| encoder.layers.encoder_layer_23.self_attention.in_proj_weight  |  3145728   |\n",
      "|  encoder.layers.encoder_layer_23.self_attention.in_proj_bias   |    3072    |\n",
      "| encoder.layers.encoder_layer_23.self_attention.out_proj.weight |  1048576   |\n",
      "|  encoder.layers.encoder_layer_23.self_attention.out_proj.bias  |    1024    |\n",
      "|          encoder.layers.encoder_layer_23.ln_2.weight           |    1024    |\n",
      "|           encoder.layers.encoder_layer_23.ln_2.bias            |    1024    |\n",
      "|      encoder.layers.encoder_layer_23.mlp.linear_1.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_23.mlp.linear_1.bias        |    4096    |\n",
      "|      encoder.layers.encoder_layer_23.mlp.linear_2.weight       |  4194304   |\n",
      "|       encoder.layers.encoder_layer_23.mlp.linear_2.bias        |    1024    |\n",
      "|                       encoder.ln.weight                        |    1024    |\n",
      "|                        encoder.ln.bias                         |    1024    |\n",
      "|                       heads.head.weight                        |  1024000   |\n",
      "|                        heads.head.bias                         |    1000    |\n",
      "+----------------------------------------------------------------+------------+\n",
      "Total Trainable Params: 306535400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "306535400"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_model =  models.vit_l_32(pretrained=True) #vit_b_32 = models.vit_b_32(pretrained=True)\n",
    "count_parameters(example_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ea5890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 1024, kernel_size=(32, 32), stride=(32, 32))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_12): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_13): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_14): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_15): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_16): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_17): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_18): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_19): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_20): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_21): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_22): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_23): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
      "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(example_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a5c961d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(example_model.heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f9e87ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_token']\n",
      "['conv_proj', 'weight']\n",
      "['conv_proj', 'bias']\n",
      "['encoder', 'pos_embedding']\n",
      "['encoder', 'layers', 'encoder_layer_0', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_0', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_0', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_0', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_0', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_0', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_0', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_0', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_0', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_0', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_0', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_0', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_1', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_1', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_1', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_1', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_1', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_1', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_1', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_1', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_1', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_1', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_1', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_1', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_2', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_2', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_2', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_2', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_2', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_2', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_2', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_2', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_2', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_2', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_2', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_2', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_3', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_3', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_3', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_3', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_3', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_3', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_3', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_3', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_3', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_3', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_3', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_3', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_4', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_4', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_4', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_4', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_4', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_4', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_4', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_4', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_4', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_4', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_4', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_4', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_5', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_5', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_5', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_5', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_5', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_5', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_5', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_5', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_5', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_5', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_5', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_5', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_6', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_6', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_6', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_6', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_6', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_6', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_6', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_6', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_6', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_6', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_6', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_6', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_7', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_7', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_7', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_7', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_7', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_7', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_7', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_7', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_7', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_7', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_7', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_7', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_8', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_8', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_8', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_8', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_8', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_8', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_8', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_8', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_8', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_8', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_8', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_8', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_9', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_9', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_9', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_9', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_9', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_9', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_9', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_9', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_9', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_9', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_9', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_9', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_10', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_10', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_10', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_10', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_10', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_10', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_10', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_10', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_10', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_10', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_10', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_10', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_11', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_11', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_11', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_11', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_11', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_11', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_11', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_11', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_11', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_11', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_11', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_11', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_12', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_12', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_12', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_12', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_12', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_12', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_12', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_12', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_12', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_12', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_12', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_12', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_13', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_13', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_13', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_13', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_13', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_13', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_13', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_13', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_13', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_13', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_13', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_13', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_14', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_14', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_14', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_14', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_14', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_14', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_14', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_14', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_14', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_14', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_14', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_14', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_15', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_15', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_15', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_15', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_15', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_15', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_15', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_15', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_15', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_15', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_15', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_15', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_16', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_16', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_16', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_16', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_16', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_16', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_16', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_16', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_16', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_16', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_16', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_16', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_17', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_17', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_17', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_17', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_17', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_17', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_17', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_17', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_17', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_17', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_17', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_17', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_18', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_18', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_18', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_18', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_18', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_18', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_18', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_18', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_18', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_18', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_18', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_18', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_19', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_19', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_19', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_19', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_19', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_19', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_19', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_19', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_19', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_19', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_19', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_19', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_20', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_20', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_20', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_20', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_20', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_20', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_20', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_20', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_20', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_20', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_20', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_20', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_21', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_21', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_21', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_21', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_21', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_21', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_21', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_21', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_21', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_21', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_21', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_21', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_22', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_22', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_22', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_22', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_22', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_22', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_22', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_22', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_22', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_22', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_22', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_22', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_23', 'ln_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_23', 'ln_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_23', 'self_attention', 'in_proj_weight']\n",
      "['encoder', 'layers', 'encoder_layer_23', 'self_attention', 'in_proj_bias']\n",
      "['encoder', 'layers', 'encoder_layer_23', 'self_attention', 'out_proj', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_23', 'self_attention', 'out_proj', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_23', 'ln_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_23', 'ln_2', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_23', 'mlp', 'linear_1', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_23', 'mlp', 'linear_1', 'bias']\n",
      "['encoder', 'layers', 'encoder_layer_23', 'mlp', 'linear_2', 'weight']\n",
      "['encoder', 'layers', 'encoder_layer_23', 'mlp', 'linear_2', 'bias']\n",
      "['encoder', 'ln', 'weight']\n",
      "['encoder', 'ln', 'bias']\n",
      "['heads', 'head', 'weight']\n",
      "['heads', 'head', 'bias']\n"
     ]
    }
   ],
   "source": [
    "for name, param in example_model.named_parameters():\n",
    "    number = name.split('.')\n",
    "    print(number)\n",
    "    #if number[0] == 'layers':\n",
    "        #print(number[1].split('_')[2])\n",
    "        #print(number[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0610f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferViT_l_32(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vit = models.vit_l_32(pretrained=True)\n",
    "        #self.conv_layer = self.get_conv_proj()\n",
    "        self.vit.heads = self.get_fc_layers()\n",
    "        #self.vit = self.get_ViT_encoder()\n",
    "        #self.fc_model = self.get_fc_layers()\n",
    "        self.activate_training_layers()\n",
    "\n",
    "    def activate_training_layers(self):\n",
    "#         for name, param in self.conv_layer.named_parameters():\n",
    "#             # for all of these layers set param.requires_grad as True\n",
    "#             param.requires_grad = False\n",
    "\n",
    "        for name, param in self.vit.named_parameters():\n",
    "            number = name.split('.')\n",
    "            # for all layers except the last conv layer, set param.requires_grad = False\n",
    "            if number[0] == 'heads':\n",
    "#                 if number[1].split('_')[2] == 11 and number[2] == 'mlp':\n",
    "#                     param.requires_grad = True\n",
    "#                 else:\n",
    "                param.requires_grad = True\n",
    "                print('required_grad = True', number)\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "                print('required_grad = False', number)\n",
    "                \n",
    "        #for name, param in self.vit.heads.named_parameters():\n",
    "            # for all of these layers set param.requires_grad as True\n",
    "           \n",
    "\n",
    "#     def get_conv_proj(self):\n",
    "#         return self.base_ViT.conv_proj\n",
    "    \n",
    "#     def get_ViT_encoder(self):\n",
    "#         return self.base_ViT.encoder\n",
    "\n",
    "    def get_fc_layers(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=1024, out_features=512, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=512, out_features=128, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=128, out_features=15, bias=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = self.conv_layer(x)\n",
    "        x = self.vit(x)\n",
    "        #x = torch.flatten(x, 1)\n",
    "        #x = self.fc_model(x)  #call fully connected layers  \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ca39091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required_grad = False ['class_token']\n",
      "required_grad = False ['conv_proj', 'weight']\n",
      "required_grad = False ['conv_proj', 'bias']\n",
      "required_grad = False ['encoder', 'pos_embedding']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_0', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_0', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_0', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_0', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_0', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_0', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_0', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_0', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_0', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_0', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_0', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_0', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_1', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_1', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_1', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_1', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_1', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_1', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_1', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_1', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_1', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_1', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_1', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_1', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_2', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_2', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_2', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_2', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_2', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_2', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_2', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_2', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_2', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_2', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_2', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_2', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_3', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_3', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_3', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_3', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_3', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_3', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_3', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_3', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_3', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_3', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_3', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_3', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_4', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_4', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_4', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_4', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_4', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_4', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_4', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_4', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_4', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_4', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_4', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_4', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_5', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_5', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_5', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_5', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_5', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_5', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_5', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_5', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_5', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_5', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_5', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_5', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_6', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_6', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_6', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_6', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_6', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_6', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_6', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_6', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_6', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_6', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_6', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_6', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_7', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_7', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_7', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_7', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_7', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_7', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_7', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_7', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_7', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_7', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_7', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_7', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_8', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_8', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_8', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_8', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_8', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_8', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_8', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_8', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_8', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_8', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_8', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_8', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_9', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_9', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_9', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_9', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_9', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_9', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_9', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_9', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_9', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_9', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_9', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_9', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_10', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_10', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_10', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_10', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_10', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_10', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_10', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_10', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_10', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_10', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_10', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_10', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_11', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_11', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_11', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_11', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_11', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_11', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_11', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_11', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_11', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_11', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_11', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_11', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_12', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_12', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_12', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_12', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_12', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_12', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_12', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_12', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_12', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_12', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_12', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_12', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_13', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_13', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_13', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_13', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_13', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_13', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_13', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_13', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_13', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_13', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_13', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_13', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_14', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_14', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_14', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_14', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_14', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_14', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_14', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_14', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_14', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_14', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_14', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_14', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_15', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_15', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_15', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_15', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_15', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_15', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_15', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_15', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_15', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_15', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_15', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_15', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_16', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_16', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_16', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_16', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_16', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_16', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_16', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_16', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_16', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_16', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_16', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_16', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_17', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_17', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_17', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_17', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_17', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_17', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_17', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_17', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_17', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_17', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_17', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_17', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_18', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_18', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_18', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_18', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_18', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_18', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_18', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_18', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_18', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_18', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_18', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_18', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_19', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_19', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_19', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_19', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_19', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_19', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_19', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_19', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_19', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_19', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_19', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_19', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_20', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_20', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_20', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_20', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_20', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_20', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_20', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_20', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_20', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_20', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_20', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_20', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_21', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_21', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_21', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_21', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_21', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_21', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_21', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_21', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_21', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_21', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_21', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_21', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_22', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_22', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_22', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_22', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_22', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_22', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_22', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_22', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_22', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_22', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_22', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_22', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_23', 'ln_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_23', 'ln_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_23', 'self_attention', 'in_proj_weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_23', 'self_attention', 'in_proj_bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_23', 'self_attention', 'out_proj', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_23', 'self_attention', 'out_proj', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_23', 'ln_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_23', 'ln_2', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_23', 'mlp', 'linear_1', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_23', 'mlp', 'linear_1', 'bias']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_23', 'mlp', 'linear_2', 'weight']\n",
      "required_grad = False ['encoder', 'layers', 'encoder_layer_23', 'mlp', 'linear_2', 'bias']\n",
      "required_grad = False ['encoder', 'ln', 'weight']\n",
      "required_grad = False ['encoder', 'ln', 'bias']\n",
      "required_grad = True ['heads', '1', 'weight']\n",
      "required_grad = True ['heads', '1', 'bias']\n",
      "required_grad = True ['heads', '4', 'weight']\n",
      "required_grad = True ['heads', '4', 'bias']\n",
      "required_grad = True ['heads', '6', 'weight']\n",
      "required_grad = True ['heads', '6', 'bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|                                                 | 1999/5377 [12:53<21:38,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|                    | 3999/5377 [25:46<08:48,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  4000] loss: 0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5377/5377 [34:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training Epoch Accuracy:75.0652445581098\n",
      "Epoch: 1 Validation Epoch Accuracy:76.74369943271645\n",
      "Epoch: 1 Correct predictions {0: 50, 1: 1983, 2: 4002, 3: 8854, 4: 186, 5: 4675, 6: 133, 7: 1917, 8: 245, 9: 521, 10: 8826, 11: 921, 12: 395, 13: 284, 14: 17}\n",
      "Epoch: 1 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 1 Correct predictions {0: 50, 1: 1983, 2: 4002, 3: 8854, 4: 186, 5: 4675, 6: 133, 7: 1917, 8: 245, 9: 521, 10: 8826, 11: 921, 12: 395, 13: 284, 14: 17}\n",
      "Epoch: 1 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 0 ! Time used: 2615.5640823841095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|                                                 | 1999/5377 [12:53<21:46,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  2000] loss: 0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|                    | 3999/5377 [25:42<08:50,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  4000] loss: 0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5377/5377 [34:32<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Training Epoch Accuracy:80.09358016797931\n",
      "Epoch: 2 Validation Epoch Accuracy:78.55249697758765\n",
      "Epoch: 2 Correct predictions {0: 49, 1: 1998, 2: 4455, 3: 8534, 4: 190, 5: 4808, 6: 136, 7: 1769, 8: 246, 9: 538, 10: 9467, 11: 902, 12: 395, 13: 283, 14: 17}\n",
      "Epoch: 2 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 2 Correct predictions {0: 49, 1: 1998, 2: 4455, 3: 8534, 4: 190, 5: 4808, 6: 136, 7: 1769, 8: 246, 9: 538, 10: 9467, 11: 902, 12: 395, 13: 283, 14: 17}\n",
      "Epoch: 2 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 1 ! Time used: 2607.7863669395447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|                                                 | 1999/5377 [12:51<21:50,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  2000] loss: 0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|                    | 3999/5377 [25:38<08:43,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  4000] loss: 0.530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5377/5377 [34:28<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Training Epoch Accuracy:81.43683338661397\n",
      "Epoch: 3 Validation Epoch Accuracy:76.75997396075513\n",
      "Epoch: 3 Correct predictions {0: 50, 1: 2045, 2: 4279, 3: 8769, 4: 185, 5: 4805, 6: 135, 7: 2202, 8: 244, 9: 553, 10: 7960, 11: 1092, 12: 396, 13: 284, 14: 17}\n",
      "Epoch: 3 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 3 Correct predictions {0: 50, 1: 2045, 2: 4279, 3: 8769, 4: 185, 5: 4805, 6: 135, 7: 2202, 8: 244, 9: 553, 10: 7960, 11: 1092, 12: 396, 13: 284, 14: 17}\n",
      "Epoch: 3 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 2 ! Time used: 2605.05811047554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|                                                 | 1999/5377 [12:52<21:27,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  2000] loss: 0.510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|                    | 3999/5377 [25:39<08:50,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  4000] loss: 0.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5377/5377 [34:27<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Training Epoch Accuracy:82.0535325060304\n",
      "Epoch: 4 Validation Epoch Accuracy:78.18283269785177\n",
      "Epoch: 4 Correct predictions {0: 50, 1: 2014, 2: 4271, 3: 8793, 4: 191, 5: 4846, 6: 138, 7: 2232, 8: 244, 9: 535, 10: 8629, 11: 985, 12: 400, 13: 283, 14: 17}\n",
      "Epoch: 4 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 4 Correct predictions {0: 50, 1: 2014, 2: 4271, 3: 8793, 4: 191, 5: 4846, 6: 138, 7: 2232, 8: 244, 9: 535, 10: 8629, 11: 985, 12: 400, 13: 283, 14: 17}\n",
      "Epoch: 4 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 3 ! Time used: 2602.013230085373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|                                                 | 1999/5377 [12:54<21:27,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  2000] loss: 0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|                    | 3999/5377 [25:39<08:46,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  4000] loss: 0.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5377/5377 [34:41<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Training Epoch Accuracy:82.50050858786945\n",
      "Epoch: 5 Validation Epoch Accuracy:81.49818655258997\n",
      "Epoch: 5 Correct predictions {0: 51, 1: 2032, 2: 3500, 3: 9769, 4: 186, 5: 4936, 6: 133, 7: 1903, 8: 245, 9: 527, 10: 9819, 11: 1256, 12: 398, 13: 282, 14: 17}\n",
      "Epoch: 5 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 5 Correct predictions {0: 51, 1: 2032, 2: 3500, 3: 9769, 4: 186, 5: 4936, 6: 133, 7: 1903, 8: 245, 9: 527, 10: 9819, 11: 1256, 12: 398, 13: 282, 14: 17}\n",
      "Epoch: 5 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 4 ! Time used: 2621.1499495506287\n",
      "Done training!\n"
     ]
    }
   ],
   "source": [
    "# Train a transfer learning model with Alexnet\n",
    "name = 'TransferViT_l_32'\n",
    "classes = [i for i in range(15)]\n",
    "transforms = get_transform('TransferViT')\n",
    "dataloaders = {'train_image_paths': train_image_paths, 'train_labels' : train_labels, 'valid_image_paths': valid_image_paths, 'valid_labels':valid_labels, 'transforms':transforms, 'sampler':sampler}\n",
    "parameters = {'lr': 0.001, 'epochs' : 5, 'batch_size':32, 'shuffle':False, 'class_names':classes}\n",
    "\n",
    "model = TransferViT_l_32()\n",
    "classifier = Classifier(name, model, dataloaders, parameters, use_cuda=True)\n",
    "classifier.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1f0c3a",
   "metadata": {},
   "source": [
    "# Data Augmentations for scarse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e75732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out the ratio of different labels/data\n",
    "\n",
    "# we decide to augment the scarser data in the following scheme: label 0, + 400, label 14 + 500, label 6 + 200\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
