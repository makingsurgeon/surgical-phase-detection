{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a3c64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from itertools import count\n",
    "import natsort\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57ad8105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import glob\n",
    "import numpy\n",
    "import random\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8edee91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 11.3\n",
      "ID of current CUDA device: 0\n",
      "Name of current CUDA device: NVIDIA GeForce RTX 2070 Super\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
    "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f88d9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1e676fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(224,224),\n",
    "        A.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d620ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths = []\n",
    "train_data_path = r\"C:\\Users\\panji\\EECS6691_Advanced_DL\\Assignment2\\training_data_images\"\n",
    "train_image_paths.append(glob.glob(train_data_path + '/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d68c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack the listed list\n",
    "train_image_paths1 = [item for sublist in train_image_paths for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "597519b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths1 = natsort.natsorted(train_image_paths1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcf97a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1967\n"
     ]
    }
   ],
   "source": [
    "print(len(train_image_paths1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98df7205",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Processed_data.csv\")\n",
    "df1 = df.loc[:,\"Phases\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf8a93a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1967\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.tolist()\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b98d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.DataFrame(\n",
    "    {'Link': train_image_paths1,\n",
    "     'Label': df2,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56c94a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train1 = dataset_train.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1764c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths = dataset_train1.loc[:,\"Link\"].to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67c80e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset_train1.loc[:,\"Label\"].to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd8fb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths, valid_image_paths = train_image_paths[:int(0.8*len(train_image_paths))], train_image_paths[int(0.8*len(train_image_paths)):]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb761b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, valid_labels = labels[:int(0.8*len(labels))], labels[int(0.8*len(labels)):] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e3d526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurgicalDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=False):\n",
    "        super(SurgicalDataset, self).__init__()\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels    #.astype(dtype='int')\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1273cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SurgicalDataset(train_image_paths,train_labels, train_transforms)\n",
    "val_dataset = SurgicalDataset(valid_image_paths,valid_labels, train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6e34aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    val_dataset, batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65b28896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=44944, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 53 * 53, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2beeae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1494acf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:21<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.019352436065674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:10<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.257498979568481\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    t = time.time()\n",
    "    running_loss = 0.0\n",
    "    loop = tqdm.tqdm(train_loader, total = len(train_loader), leave = True)\n",
    "    for img, label in loop:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = img.to(device), label.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "    d = time.time()-t\n",
    "    print(d)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "661789f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 15, 1: 26, 2: 19, 3: 15, 4: 30, 5: 111, 6: 0, 7: 8, 8: 34, 9: 0, 10: 80}\n",
      "{0: 15, 1: 43, 2: 24, 3: 16, 4: 35, 5: 114, 6: 6, 7: 11, 8: 41, 9: 2, 10: 87}\n"
     ]
    }
   ],
   "source": [
    "classes = [i for i in range(11)]\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in valid_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "print(correct_pred)\n",
    "print(total_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b2e2e0",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be4caaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut frames from videos\n",
    "for i in range(1,4):\n",
    "    vidcap = cv2.VideoCapture(\"RALIHR_surgeon01_fps01_000%d.mp4\"% i)\n",
    "    #print(\"RALIHR_surgeon01_fps01_000%d.mp4\"% i)\n",
    "    success, image = vidcap.read()\n",
    "    #print(vidcap)\n",
    "    #print(image)\n",
    "    count = 0\n",
    "    while success:\n",
    "        cv2.imwrite(r'\\training_data_images\\Video%dframe%d.jpg'% (i, count), image)\n",
    "        success,image = vidcap.read()\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3d3497d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VideoCapture 000001DB02AEC730>\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "vidcap = cv2.VideoCapture(\"RALIHR_surgeon01_fps01_0001.mp4\")\n",
    "# vidcap = cv2.VideoCapture(\"RALIHR_surgeon01_fps01_000%d.mp4\"% i)\n",
    "print(vidcap)\n",
    "success, image = vidcap.read()\n",
    "print(success)\n",
    "success, image = vidcap.read()\n",
    "print(success)\n",
    "#print(image)\n",
    "count = 0\n",
    "while success:\n",
    "    cv2.imwrite(r'C:\\Users\\panji\\EECS6691_Advanced_DL\\Assignment2\\training_data_images\\Video%dframe%d.jpg'% (1, count), image)\n",
    "    success,image = vidcap.read()\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13b6cb1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                         videoName             PhaseName  Start    End\n",
      "0     RALIHR_surgeon01_fps01_0001                Access    ---    ---\n",
      "1     RALIHR_surgeon01_fps01_0001      Stationary Idle1  00:00  00:16\n",
      "2     RALIHR_surgeon01_fps01_0001   Transitionary Idle1  00:16  00:35\n",
      "3     RALIHR_surgeon01_fps01_0001           Out of body  00:35  01:05\n",
      "4     RALIHR_surgeon01_fps01_0001   Transitionary Idle2  01:05  01:59\n",
      "...                           ...                   ...    ...    ...\n",
      "2020  RALIHR_surgeon01_fps01_0070   Peritoneal closure8  51:24  52:23\n",
      "2021  RALIHR_surgeon01_fps01_0070  Positioning suture11  52:23  54:08\n",
      "2022  RALIHR_surgeon01_fps01_0070   Peritoneal closure9  54:08  57:27\n",
      "2023  RALIHR_surgeon01_fps01_0070  Positioning suture12  57:27  57:55\n",
      "2024  RALIHR_surgeon01_fps01_0070  Transitionary Idle11  57:55  58:18\n",
      "\n",
      "[2025 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "#Get labels\n",
    "a =  pd.read_csv(\"video.phase.trainingData.clean.StudentVersion.csv\")\n",
    "print(a.head)\n",
    "a1 = a[a.PhaseName !=\"Access\"]\n",
    "a2 = a1\n",
    "\n",
    "for i in range(a2.shape[0]):\n",
    "    if any([c.isdigit() for c in a2.iat[i,1]]):\n",
    "        a2.iat[i,1] = a2.iat[i,1][:-1]\n",
    "    a2.iat[i,1] = a2.iat[i,1].lower()\n",
    "b1 = a2[\"PhaseName\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83d5569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimeChange(a):\n",
    "    if len(a) != 8:\n",
    "        x = time.strptime(a,'%M:%S')\n",
    "        x1 = int(datetime.timedelta(minutes = x.tm_min, seconds = x.tm_sec).total_seconds())\n",
    "    elif len(a) == 8 and a[:2] == \"00\":\n",
    "        a = a[3:]\n",
    "        x = time.strptime(a,'%M:%S')\n",
    "        x1 = int(datetime.timedelta(minutes = x.tm_min, seconds = x.tm_sec).total_seconds())\n",
    "    else:\n",
    "        x = time.strptime(a,'%H:%M:%S')\n",
    "        x1 = int(datetime.timedelta(hours = x.tm_hour, minutes = x.tm_min, seconds = x.tm_sec).total_seconds())\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93224f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices= []\n",
    "phases =[]\n",
    "for i in range(23):\n",
    "    index = int(a2.iloc[i,0][-2:])\n",
    "    start_time = int(TimeChange(a2.iloc[i,2]))\n",
    "    end_time = int(TimeChange(a2.iloc[i,3]))\n",
    "    indices1 = [index]*(end_time-start_time)\n",
    "    indices.extend(indices1)\n",
    "    phases1 = [int(np.where(b1==a2.iloc[i,1])[0])]*(end_time-start_time)\n",
    "    phases.extend(phases1)\n",
    "x2 = {\"Video\":indices, \"Phases\": phases}\n",
    "df = pd.DataFrame(x2, columns = [\"Video\", \"Phases\"])\n",
    "df.to_csv(\"Processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb04d2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n",
      "106.35212660731949\n"
     ]
    }
   ],
   "source": [
    "print(a2.shape[0])\n",
    "print(215044/a2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc09e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
