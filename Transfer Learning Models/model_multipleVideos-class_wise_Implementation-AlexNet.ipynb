{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a3c64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from itertools import count\n",
    "import natsort\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ad8105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d9cb19a130>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import glob\n",
    "import numpy\n",
    "import random\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8edee91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 11.3\n",
      "ID of current CUDA device: 0\n",
      "Name of current CUDA device: NVIDIA GeForce RTX 2070 Super\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
    "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558e2fa",
   "metadata": {},
   "source": [
    "# Building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3d526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurgicalDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=False):\n",
    "        super(SurgicalDataset, self).__init__()\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels    #.astype(dtype='int')\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        \n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4fde70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(model_name):\n",
    "\n",
    "    if model_name == 'alexnet':\n",
    "        transform = A.Compose([\n",
    "            A.Resize(227, 227),\n",
    "            A.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    else:\n",
    "\n",
    "        transform = A.Compose([\n",
    "            A.Resize(224,224),\n",
    "            A.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a405b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_image_paths1) 215057\n",
      "len(df2) 215057\n",
      "train_labels 172045\n",
      "train_image_paths 172045\n",
      "label distribution in the training data [  243  8681 22901 41140   952 22305   666 10930   896  2308 44928 12987\n",
      "  1789  1246    73]\n"
     ]
    }
   ],
   "source": [
    "# Preparing the datasets\n",
    "# Get images\n",
    "train_image_paths = []\n",
    "train_data_path = r\"C:\\Users\\panji\\EECS6691_Advanced_DL\\Assignment2\\training_data_images\"\n",
    "train_image_paths.append(glob.glob(train_data_path + '/*'))\n",
    "# unpack the listed list\n",
    "train_image_paths1 = [item for sublist in train_image_paths for item in sublist]\n",
    "train_image_paths1 = natsort.natsorted(train_image_paths1)\n",
    "print('len(train_image_paths1)', len(train_image_paths1))\n",
    "\n",
    "# Get labels\n",
    "df = pd.read_csv(\"Processed_data.csv\")\n",
    "df1 = df.loc[:,\"Phases\"].to_numpy()\n",
    "df2 = df1.tolist()\n",
    "print('len(df2)', len(df2))\n",
    "\n",
    "# Preparing the datasets (images and labels)\n",
    "dataset_train = pd.DataFrame(\n",
    "    {'Link': train_image_paths1,\n",
    "     'Label': df2,\n",
    "    })\n",
    "dataset_train1 = dataset_train.sample(frac=1, random_state=1)\n",
    "train_image_paths = dataset_train1.loc[:,\"Link\"].to_numpy().tolist()\n",
    "labels = dataset_train1.loc[:,\"Label\"].to_numpy().tolist()\n",
    "\n",
    "# manually split the dataset\n",
    "train_image_paths, valid_image_paths = train_image_paths[:int(0.8*len(train_image_paths))], train_image_paths[int(0.8*len(train_image_paths)):]  \n",
    "train_labels, valid_labels = labels[:int(0.8*len(labels))], labels[int(0.8*len(labels)):] \n",
    "print('train_labels', len(train_labels))\n",
    "print('train_image_paths', len(train_image_paths))\n",
    "print('label distribution in the training data', np.bincount(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654abaf3",
   "metadata": {},
   "source": [
    "# Weighted Data Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82e1ef5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df2) 215057\n",
      "{0: 243, 1: 8681, 2: 22901, 3: 41140, 4: 952, 5: 22305, 6: 666, 7: 10930, 8: 896, 9: 2308, 10: 44928, 11: 12987, 12: 1789, 13: 1246, 14: 73}\n",
      "172045\n",
      "15\n",
      "172045\n",
      "172045\n"
     ]
    }
   ],
   "source": [
    "# from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# Get labels\n",
    "df = pd.read_csv(\"Processed_data.csv\")\n",
    "df1 = df.loc[:,\"Phases\"].to_numpy()\n",
    "df2 = df1.tolist()\n",
    "print('len(df2)', len(df2))\n",
    "\n",
    "# Preparing the datasets (images and labels)\n",
    "dataset_train = pd.DataFrame(\n",
    "    {'Link': train_image_paths1,\n",
    "     'Label': df2,\n",
    "    })\n",
    "dataset_train1 = dataset_train.sample(frac=1, random_state=1)\n",
    "train_image_paths = dataset_train1.loc[:,\"Link\"].to_numpy().tolist()\n",
    "labels = dataset_train1.loc[:,\"Label\"].to_numpy().tolist()\n",
    "\n",
    "summary = {i:0 for i in range(15)}\n",
    "num_classes = 15\n",
    "total_samples = 0\n",
    "for i in train_labels:\n",
    "    total_samples += 1\n",
    "    summary[i] += 1\n",
    "print(summary)\n",
    "print(total_samples)\n",
    "\n",
    "class_weights = [total_samples/summary[i] for i in range(num_classes)]\n",
    "weights = [class_weights[train_labels[i]] for i in range(total_samples)]\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(weights), len(weights))\n",
    "print(len(class_weights))\n",
    "print(len(weights))\n",
    "print(len(list(sampler)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb10568",
   "metadata": {},
   "source": [
    "# Building the classifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b4e3a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier():\n",
    "\n",
    "    def __init__(self, name, model, dataloaders, parameter, use_cuda=False):\n",
    "        \n",
    "        '''\n",
    "        @name: Experiment name. Will define stored results etc. \n",
    "        @model: Any models\n",
    "        @dataloaders: Dictionary with keys train, val and test and corresponding dataloaders\n",
    "        @class_names: list of classes, where the idx of class name corresponds to the label used for it in the data\n",
    "        @use_cuda: whether or not to use cuda\n",
    "        '''\n",
    "       \n",
    "        self.name = name\n",
    "        if use_cuda and not torch.cuda.is_available():\n",
    "            raise Exception(\"Asked for CUDA but GPU not found\")\n",
    "            \n",
    "        self.use_cuda = use_cuda\n",
    "        self.epoch = parameter['epochs']\n",
    "        self.lr = parameter['lr']\n",
    "        self.batch_size = parameter['batch_size']\n",
    "        \n",
    "        self.model = model.to('cuda' if use_cuda else 'cpu') # model.to('cpu')\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.train_loader, self.valid_loader = self.get_dataloaders(dataloaders['train_image_paths'], \n",
    "                                                                    dataloaders['train_labels'], \n",
    "                                                                    dataloaders['valid_image_paths'], \n",
    "                                                                    dataloaders['valid_labels'], \n",
    "                                                                    train_transforms=dataloaders['transforms'], \n",
    "                                                                    batch_size = self.batch_size,\n",
    "                                                                    shuffle=parameter['shuffle'],\n",
    "                                                                   sampler = dataloaders['sampler'])\n",
    "        self.class_names = parameter['class_names']\n",
    "        \n",
    "        self.activations_path = os.path.join('activations', self.name)\n",
    "        self.kernel_path = os.path.join('kernel_viz', self.name)\n",
    "        save_path = os.path.join(os.getcwd(), 'models', self.name)\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        if not os.path.exists(self.activations_path):\n",
    "            os.makedirs(self.activations_path)\n",
    "\n",
    "        if not os.path.exists(self.kernel_path):\n",
    "            os.makedirs(self.kernel_path)\n",
    "            \n",
    "        self.save_path = save_path\n",
    "\n",
    "    def train(self, save=True):\n",
    "        '''\n",
    "        @epochs: number of epochs to train\n",
    "        @save: whether or not to save the checkpoints\n",
    "        '''\n",
    "        best_val_accuracy = - math.inf\n",
    "        \n",
    "        for epoch in range(self.epoch):  # loop over the dataset multiple times\n",
    "            self.model.train()\n",
    "            t = time.time()\n",
    "            running_loss = 0.0\n",
    "            train_acc = 0\n",
    "            val_accuracy = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            count = 0\n",
    "            loop = tqdm.tqdm(self.train_loader, total = len(self.train_loader), leave = True)\n",
    "            \n",
    "            for img, label in loop:\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = img.to(device), label.to(device) #img.to(device), label.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = self.model(inputs)\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                total += labels.shape[0]\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                \n",
    "                count += 1\n",
    "                if count % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                    print(f'[{epoch + 1}, {count + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                    running_loss = 0.0\n",
    "                    \n",
    "            train_acc = 100 * correct / total\n",
    "            print(f'Epoch:', epoch + 1, f'Training Epoch Accuracy:{train_acc}')\n",
    "            \n",
    "            # evaluate the validation dataset\n",
    "            self.model.eval()\n",
    "            correct_pred = {classname: 0 for classname in self.class_names}\n",
    "            total_pred = {classname: 0 for classname in self.class_names}\n",
    "\n",
    "            # again no gradients needed\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data in self.valid_loader:\n",
    "                    images, labels = data[0].to(device), data[1].to(device) #data[0], data[1]\n",
    "                    outputs = self.model(images)\n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    # collect the correct predictions for each class\n",
    "                    total += labels.shape[0]\n",
    "                    correct += (predictions == labels).sum().item()\n",
    "\n",
    "                    for label, prediction in zip(labels, predictions):\n",
    "                        if label == prediction:\n",
    "                            correct_pred[classes[label]] += 1\n",
    "                        total_pred[classes[label]] += 1\n",
    "\n",
    "            val_accuracy = 100 * correct / total\n",
    "            print(f'Epoch:', epoch + 1, f'Validation Epoch Accuracy:{val_accuracy}')\n",
    "                        \n",
    "            # print the summary for each class\n",
    "            print('Epoch:', epoch + 1, 'Correct predictions', correct_pred)\n",
    "            print('Epoch:', epoch + 1, 'Total predictions', total_pred)\n",
    "            print('Epoch:', epoch + 1, 'Correct predictions', correct_pred)\n",
    "            print('Epoch:', epoch + 1, 'Total predictions', total_pred)\n",
    "            \n",
    "            # inspect the time taken to train one epoch\n",
    "            d = time.time()-t\n",
    "            print('Fininsh Trainig Epoch', epoch, '!', 'Time used:', d)\n",
    "            \n",
    "            if save:\n",
    "                torch.save(self.model.state_dict(), os.path.join(self.save_path, f'epoch_{epoch}.pt'))\n",
    "                if val_accuracy > best_val_accuracy:\n",
    "                    torch.save(self.model.state_dict(), os.path.join(self.save_path, 'best.pt'))\n",
    "                    best_val_accuracy = val_accuracy\n",
    "\n",
    "        print('Done training!')                       \n",
    "\n",
    "    \n",
    "    def evaluate(self):\n",
    "        # for evaluating the test dataset if there were any.\n",
    "        try:\n",
    "            assert os.path.exists(os.path.join(self.save_path, 'best.pt'))\n",
    "            \n",
    "        except:\n",
    "            print('Please train first')\n",
    "            return\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(os.path.join(self.save_path, 'best.pt')))\n",
    "        self.model.eval()\n",
    "        \n",
    "    def get_dataloaders(self, train_image_paths, train_labels, valid_image_paths, valid_labels, train_transforms=False, batch_size=32, shuffle=True, sampler = None):\n",
    "        train_dataset = SurgicalDataset(train_image_paths,train_labels, train_transforms)\n",
    "        val_dataset = SurgicalDataset(valid_image_paths,valid_labels, train_transforms)\n",
    "        train_loader = DataLoader(train_dataset, batch_size, shuffle, sampler)\n",
    "        valid_loader = DataLoader(val_dataset, batch_size, shuffle = True)\n",
    "        return train_loader, valid_loader\n",
    "    \n",
    "    def grad_cam_on_input(self, img):\n",
    "        \n",
    "        try:\n",
    "            assert os.path.exists(os.path.join(self.save_path, 'best.pt'))\n",
    "\n",
    "        except:\n",
    "            print('It appears you are testing the model without training. Please train first')\n",
    "            return\n",
    "\n",
    "        self.model.load_state_dict(torch.load(os.path.join(self.save_path, 'best.pt')))\n",
    "\n",
    "\n",
    "        self.model.eval()\n",
    "        img = img.to('cuda' if self.use_cuda else 'cpu')\n",
    "\n",
    "\n",
    "        out = self.model(img)\n",
    "\n",
    "        _, pred = torch.max(out, 1)\n",
    "\n",
    "        predicted_class = self.class_names[int(pred)]\n",
    "        print(f'Predicted class was {predicted_class}')\n",
    "\n",
    "        out[:, pred].backward()\n",
    "        gradients = self.model.get_gradient_activations()\n",
    "\n",
    "        print('Gradients shape: ', f'{gradients.shape}')\n",
    "\n",
    "        mean_gradients = torch.mean(gradients, [0, 2, 3]).cpu()\n",
    "        activations = self.model.get_final_conv_layer(img).detach().cpu()\n",
    "\n",
    "        print('Activations shape: ', f'{activations.shape}')\n",
    "\n",
    "        for idx in range(activations.shape[1]):\n",
    "            activations[:, idx, :, :] *= mean_gradients[idx]\n",
    "\n",
    "        final_heatmap = np.maximum(torch.mean(activations, dim=1).squeeze(), 0)\n",
    "\n",
    "        final_heatmap /= torch.max(final_heatmap)\n",
    "\n",
    "        return final_heatmap\n",
    "\n",
    "    def trained_kernel_viz(self):\n",
    "        \n",
    "        all_layers = [0, 3]\n",
    "        all_filters = []\n",
    "        for layer in all_layers:\n",
    "\n",
    "            filters = self.model.conv_model[layer].weight\n",
    "            all_filters.append(filters.detach().cpu().clone()[:8, :8, :, :])\n",
    "\n",
    "        for filter_idx in range(len(all_filters)):\n",
    "\n",
    "            filter = all_filters[filter_idx]\n",
    "            print(filter.shape)\n",
    "            filter = filter.contiguous().view(-1, 1, filter.shape[2], filter.shape[3])\n",
    "            image = show_img(make_grid(filter))\n",
    "            image = 255 * image\n",
    "            cv2.imwrite(os.path.join(self.kernel_path, f'filter_layer{all_layers[filter_idx]}.jpg'), image)\n",
    "    \n",
    "\n",
    "    def activations_on_input(self, img):\n",
    "        \n",
    "        img = img.to('cuda' if self.use_cuda else 'cpu')\n",
    "\n",
    "        all_layers = [0,3,6,8,10]\n",
    "        all_viz = []\n",
    "        \n",
    "        # looking at the outputs of the relu\n",
    "        for each in all_layers:\n",
    "\n",
    "            current_model = self.model.conv_model[:each+1]\n",
    "            current_out = current_model(img)\n",
    "            all_viz.append(current_out.detach().cpu().clone()[:, :64, :, :])\n",
    "\n",
    "        for viz_idx in range(len(all_viz)):\n",
    "\n",
    "            viz = all_viz[viz_idx]\n",
    "            viz = viz.view(-1, 1, viz.shape[2], viz.shape[3])\n",
    "            image = show_img(make_grid(viz))\n",
    "            image = 255 * image\n",
    "            cv2.imwrite(os.path.join(self.activations_path, f'sample_layer{all_layers[viz_idx]}.jpg'), image)    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c6108",
   "metadata": {},
   "source": [
    "# Build and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18d59f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "example_model = models.alexnet(pretrained=True)\n",
    "print(example_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0610f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferAlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base_alex_net = models.alexnet(pretrained=True)\n",
    "        self.conv_model = self.get_conv_layers()\n",
    "        self.final_max_pool = self.final_pool_layer()\n",
    "        self.avg_pool = self.transition_layer()\n",
    "        self.fc_model = self.get_fc_layers()\n",
    "        self.activate_training_layers()\n",
    "\n",
    "    def activate_training_layers(self):\n",
    "        for name, param in self.conv_model.named_parameters():\n",
    "            number = int(name.split('.')[0])\n",
    "            # for all layers except the last layer set param.requires_grad = False\n",
    "            if number < 10:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "                \n",
    "        for name, param in self.fc_model.named_parameters():\n",
    "            # for all of these layers set param.requires_grad as True\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def get_conv_layers(self):\n",
    "        return self.base_alex_net.features[:12]\n",
    "\n",
    "    def final_pool_layer(self):\n",
    "        return nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "\n",
    "    def transition_layer(self):\n",
    "        return nn.AdaptiveAvgPool2d(output_size=(6, 6))\n",
    "\n",
    "    def get_fc_layers(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=9216, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=4096, out_features=1000, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=1000, out_features=15, bias=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_model(x)   #call the conv layers\n",
    "        x = self.final_max_pool(x)  #call the max pool layer\n",
    "        x = self.avg_pool(x)  #call the avg pool layer\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc_model(x)  #call fully connected layers  \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b13a060f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████▌                                                          | 1999/5377 [07:26<13:20,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▏                       | 3999/5377 [14:48<05:03,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  4000] loss: 0.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5377/5377 [19:53<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training Epoch Accuracy:81.80766659885495\n",
      "Epoch: 1 Validation Epoch Accuracy:79.06630707709476\n",
      "Epoch: 1 Correct predictions {0: 50, 1: 2139, 2: 4519, 3: 6978, 4: 174, 5: 4987, 6: 141, 7: 1906, 8: 244, 9: 530, 10: 10338, 11: 1303, 12: 397, 13: 285, 14: 17}\n",
      "Epoch: 1 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 1 Correct predictions {0: 50, 1: 2139, 2: 4519, 3: 6978, 4: 174, 5: 4987, 6: 141, 7: 1906, 8: 244, 9: 530, 10: 10338, 11: 1303, 12: 397, 13: 285, 14: 17}\n",
      "Epoch: 1 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 0 ! Time used: 1607.5371115207672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████▌                                                          | 1999/5377 [08:02<13:04,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  2000] loss: 0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▏                       | 3999/5377 [15:55<05:13,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  4000] loss: 0.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5377/5377 [21:16<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Training Epoch Accuracy:89.25571798076085\n",
      "Epoch: 2 Validation Epoch Accuracy:87.80107876871571\n",
      "Epoch: 2 Correct predictions {0: 50, 1: 2102, 2: 5075, 3: 9387, 4: 177, 5: 5120, 6: 132, 7: 1977, 8: 240, 9: 554, 10: 10372, 11: 1877, 12: 402, 13: 283, 14: 17}\n",
      "Epoch: 2 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 2 Correct predictions {0: 50, 1: 2102, 2: 5075, 3: 9387, 4: 177, 5: 5120, 6: 132, 7: 1977, 8: 240, 9: 554, 10: 10372, 11: 1877, 12: 402, 13: 283, 14: 17}\n",
      "Epoch: 2 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 1 ! Time used: 1578.8561582565308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████▌                                                          | 1999/5377 [07:59<13:33,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  2000] loss: 0.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▏                       | 3999/5377 [15:38<05:17,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  4000] loss: 0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5377/5377 [20:53<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Training Epoch Accuracy:90.95062338341712\n",
      "Epoch: 3 Validation Epoch Accuracy:88.49390867664837\n",
      "Epoch: 3 Correct predictions {0: 49, 1: 2133, 2: 4844, 3: 9473, 4: 181, 5: 5173, 6: 135, 7: 2217, 8: 243, 9: 550, 10: 10291, 11: 2076, 12: 398, 13: 283, 14: 17}\n",
      "Epoch: 3 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 3 Correct predictions {0: 49, 1: 2133, 2: 4844, 3: 9473, 4: 181, 5: 5173, 6: 135, 7: 2217, 8: 243, 9: 550, 10: 10291, 11: 2076, 12: 398, 13: 283, 14: 17}\n",
      "Epoch: 3 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 2 ! Time used: 1539.0077166557312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████▌                                                          | 1999/5377 [07:37<12:33,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  2000] loss: 0.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▏                       | 3999/5377 [15:11<05:09,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  4000] loss: 0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5377/5377 [20:24<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Training Epoch Accuracy:92.13054724054753\n",
      "Epoch: 4 Validation Epoch Accuracy:90.0888124244397\n",
      "Epoch: 4 Correct predictions {0: 47, 1: 2109, 2: 5277, 3: 9753, 4: 186, 5: 5234, 6: 143, 7: 2397, 8: 244, 9: 554, 10: 10376, 11: 1730, 12: 399, 13: 283, 14: 17}\n",
      "Epoch: 4 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 4 Correct predictions {0: 47, 1: 2109, 2: 5277, 3: 9753, 4: 186, 5: 5234, 6: 143, 7: 2397, 8: 244, 9: 554, 10: 10376, 11: 1730, 12: 399, 13: 283, 14: 17}\n",
      "Epoch: 4 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 3 ! Time used: 1525.2642753124237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████▌                                                          | 1999/5377 [07:49<13:01,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  2000] loss: 0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▏                       | 3999/5377 [15:27<05:14,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  4000] loss: 0.240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5377/5377 [20:47<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Training Epoch Accuracy:93.04309918916563\n",
      "Epoch: 5 Validation Epoch Accuracy:89.69822375151121\n",
      "Epoch: 5 Correct predictions {0: 49, 1: 2117, 2: 5491, 3: 9229, 4: 163, 5: 5288, 6: 136, 7: 2370, 8: 243, 9: 561, 10: 10284, 11: 1953, 12: 399, 13: 281, 14: 17}\n",
      "Epoch: 5 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 5 Correct predictions {0: 49, 1: 2117, 2: 5491, 3: 9229, 4: 163, 5: 5288, 6: 136, 7: 2370, 8: 243, 9: 561, 10: 10284, 11: 1953, 12: 399, 13: 281, 14: 17}\n",
      "Epoch: 5 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 4 ! Time used: 1544.173043012619\n",
      "Done training!\n"
     ]
    }
   ],
   "source": [
    "# Train a transfer learning model with Alexnet\n",
    "name = 'TransferAlexNet'\n",
    "classes = [i for i in range(15)]\n",
    "transforms = get_transform('alexnet')\n",
    "dataloaders = {'train_image_paths': train_image_paths, 'train_labels' : train_labels, 'valid_image_paths': valid_image_paths, 'valid_labels':valid_labels, 'transforms':transforms, 'sampler':sampler}\n",
    "parameters = {'lr': 0.001, 'epochs' : 5, 'batch_size':32, 'shuffle':False, 'class_names':classes}\n",
    "\n",
    "model = TransferAlexNet()\n",
    "classifier = Classifier(name, model, dataloaders, parameters, use_cuda=True)\n",
    "classifier.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f36ead",
   "metadata": {},
   "source": [
    "# Data Augmentations for scarse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb79c41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out the ratio of different labels/data\n",
    "\n",
    "# we decide to augment the scarser data in the following scheme: label 0, + 400, label 14 + 500, label 6 + 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "47e0127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [2,3,6,7]\n",
    "target = 8\n",
    "# Output： [[7], [2,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dfdd1198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2]\n",
      "[2, 2, 2, 2]\n",
      "[]\n",
      "[2, 2, 2, 2]\n",
      "[]\n",
      "[]\n",
      "[3, 2, 3]\n",
      "[6, 2]\n",
      "[]\n",
      "[[2, 2, 2, 2], [3, 2, 3], [6, 2]]\n"
     ]
    }
   ],
   "source": [
    "# wrong!\n",
    "\n",
    "def recur(candidate, target, candidates):\n",
    "    #print(candidate)\n",
    "    if sum(candidate) > target:\n",
    "        return []\n",
    "    if sum(candidate) == target:\n",
    "        return candidate\n",
    "    \n",
    "    combination = []\n",
    "    candidate = candidate[:]\n",
    "    for num in candidates:\n",
    "        candidate.append(num)\n",
    "        combination.extend(recur(candidate, target, candidates))\n",
    "        \n",
    "    print(combination)  \n",
    "    return combination\n",
    "    \n",
    "output = []\n",
    "for i in candidates:\n",
    "    candidate = []\n",
    "    candidate.append(i)\n",
    "    combination = recur(candidate, target, candidates)\n",
    "    if combination: output.append(combination)\n",
    "\n",
    "print(output)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af2498cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[2, 2]\n",
      "[2, 2, 2]\n",
      "[2, 2, 2, 2]\n",
      "[2, 2, 2, 3]\n",
      "[2, 2, 2, 6]\n",
      "[2, 2, 2, 7]\n",
      "[2, 2, 3]\n",
      "[2, 2, 3, 3]\n",
      "[2, 2, 3, 6]\n",
      "[2, 2, 3, 7]\n",
      "[2, 2, 6]\n",
      "[2, 2, 7]\n",
      "[2, 3]\n",
      "[2, 3, 3]\n",
      "[2, 3, 6]\n",
      "[2, 3, 7]\n",
      "[2, 6]\n",
      "[2, 7]\n",
      "[3]\n",
      "[3, 3]\n",
      "[3, 3, 3]\n",
      "[3, 3, 6]\n",
      "[3, 3, 7]\n",
      "[3, 6]\n",
      "[3, 7]\n",
      "[6]\n",
      "[6, 6]\n",
      "[6, 7]\n",
      "[7]\n",
      "[7, 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2, 2, 2, 2], [2, 3, 3], [2, 6]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def findcomb(candidates, target):\n",
    "    res = []\n",
    "    def dfs(acc, i):\n",
    "        acc.append(candidates[i])\n",
    "        print(acc)\n",
    "        if sum(acc) == target:\n",
    "            res.append(acc[:])\n",
    "            return\n",
    "        if sum(acc) > target:\n",
    "            return\n",
    "        for j in range(i, len(candidates)):\n",
    "            #acc.append(candidates[j])\n",
    "            dfs(acc, j)\n",
    "            acc.pop()\n",
    "    \n",
    "    for i in range(len(candidates)):\n",
    "        acc = []\n",
    "        dfs(acc, i)\n",
    "    return res\n",
    "\n",
    "findcomb(candidates, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6febfd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
