{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a3c64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from itertools import count\n",
    "import natsort\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ad8105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e71d823130>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import glob\n",
    "import numpy\n",
    "import random\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8edee91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 11.3\n",
      "ID of current CUDA device: 0\n",
      "Name of current CUDA device: NVIDIA GeForce RTX 2070 Super\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
    "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848161dc",
   "metadata": {},
   "source": [
    "# Building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3d526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurgicalDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=False):\n",
    "        super(SurgicalDataset, self).__init__()\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels    #.astype(dtype='int')\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        \n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad62ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(model_name):\n",
    "\n",
    "    if model_name == 'alexnet':\n",
    "        transform = A.Compose([\n",
    "            A.Resize(227, 227),\n",
    "            A.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif model_name == 'effinet':\n",
    "        transform = A.Compose([\n",
    "            A.Resize(224, 224),\n",
    "            A.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "    else:\n",
    "\n",
    "        transform = A.Compose([\n",
    "            A.Resize(224,224),\n",
    "            A.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e030c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_image_paths1) 215057\n",
      "len(df2) 215057\n",
      "train_labels 172045\n",
      "train_image_paths 172045\n",
      "label distribution in the training data [  243  8681 22901 41140   952 22305   666 10930   896  2308 44928 12987\n",
      "  1789  1246    73]\n"
     ]
    }
   ],
   "source": [
    "# Preparing the datasets\n",
    "# Get images\n",
    "train_image_paths = []\n",
    "train_data_path = r\"C:\\Users\\panji\\EECS6691_Advanced_DL\\Assignment2\\training_data_images\"\n",
    "train_image_paths.append(glob.glob(train_data_path + '/*'))\n",
    "# unpack the listed list\n",
    "train_image_paths1 = [item for sublist in train_image_paths for item in sublist]\n",
    "train_image_paths1 = natsort.natsorted(train_image_paths1)\n",
    "print('len(train_image_paths1)', len(train_image_paths1))\n",
    "\n",
    "# Get labels\n",
    "df = pd.read_csv(\"Processed_data.csv\")\n",
    "df1 = df.loc[:,\"Phases\"].to_numpy()\n",
    "df2 = df1.tolist()\n",
    "print('len(df2)', len(df2))\n",
    "\n",
    "# Preparing the datasets (images and labels)\n",
    "dataset_train = pd.DataFrame(\n",
    "    {'Link': train_image_paths1,\n",
    "     'Label': df2,\n",
    "    })\n",
    "dataset_train1 = dataset_train.sample(frac=1, random_state=1)\n",
    "train_image_paths = dataset_train1.loc[:,\"Link\"].to_numpy().tolist()\n",
    "labels = dataset_train1.loc[:,\"Label\"].to_numpy().tolist()\n",
    "\n",
    "# manually split the dataset\n",
    "train_image_paths, valid_image_paths = train_image_paths[:int(0.8*len(train_image_paths))], train_image_paths[int(0.8*len(train_image_paths)):]  \n",
    "train_labels, valid_labels = labels[:int(0.8*len(labels))], labels[int(0.8*len(labels)):] \n",
    "print('train_labels', len(train_labels))\n",
    "print('train_image_paths', len(train_image_paths))\n",
    "print('label distribution in the training data', np.bincount(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69671af2",
   "metadata": {},
   "source": [
    "# Weighted Data Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa1ba5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df2) 215057\n",
      "{0: 243, 1: 8681, 2: 22901, 3: 41140, 4: 952, 5: 22305, 6: 666, 7: 10930, 8: 896, 9: 2308, 10: 44928, 11: 12987, 12: 1789, 13: 1246, 14: 73}\n",
      "172045\n",
      "15\n",
      "172045\n",
      "172045\n"
     ]
    }
   ],
   "source": [
    "# from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# Get labels\n",
    "df = pd.read_csv(\"Processed_data.csv\")\n",
    "df1 = df.loc[:,\"Phases\"].to_numpy()\n",
    "df2 = df1.tolist()\n",
    "print('len(df2)', len(df2))\n",
    "\n",
    "# Preparing the datasets (images and labels)\n",
    "dataset_train = pd.DataFrame(\n",
    "    {'Link': train_image_paths1,\n",
    "     'Label': df2,\n",
    "    })\n",
    "dataset_train1 = dataset_train.sample(frac=1, random_state=1)\n",
    "train_image_paths = dataset_train1.loc[:,\"Link\"].to_numpy().tolist()\n",
    "labels = dataset_train1.loc[:,\"Label\"].to_numpy().tolist()\n",
    "\n",
    "summary = {i:0 for i in range(15)}\n",
    "num_classes = 15\n",
    "total_samples = 0\n",
    "for i in train_labels:\n",
    "    total_samples += 1\n",
    "    summary[i] += 1\n",
    "print(summary)\n",
    "print(total_samples)\n",
    "\n",
    "class_weights = [total_samples/summary[i] for i in range(num_classes)]\n",
    "weights = [class_weights[train_labels[i]] for i in range(total_samples)]\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(weights), len(weights))\n",
    "print(len(class_weights))\n",
    "print(len(weights))\n",
    "print(len(list(sampler)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c62de6",
   "metadata": {},
   "source": [
    "# Building the classifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b4e3a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier():\n",
    "\n",
    "    def __init__(self, name, model, dataloaders, parameter, use_cuda=False):\n",
    "        \n",
    "        '''\n",
    "        @name: Experiment name. Will define stored results etc. \n",
    "        @model: Any models\n",
    "        @dataloaders: Dictionary with keys train, val and test and corresponding dataloaders\n",
    "        @class_names: list of classes, where the idx of class name corresponds to the label used for it in the data\n",
    "        @use_cuda: whether or not to use cuda\n",
    "        '''\n",
    "       \n",
    "        self.name = name\n",
    "        if use_cuda and not torch.cuda.is_available():\n",
    "            raise Exception(\"Asked for CUDA but GPU not found\")\n",
    "            \n",
    "        self.use_cuda = use_cuda\n",
    "        self.epoch = parameter['epochs']\n",
    "        self.lr = parameter['lr']\n",
    "        self.batch_size = parameter['batch_size']\n",
    "        \n",
    "        self.model = model.to('cuda' if use_cuda else 'cpu') # model.to('cpu')\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.train_loader, self.valid_loader = self.get_dataloaders(dataloaders['train_image_paths'], \n",
    "                                                                    dataloaders['train_labels'], \n",
    "                                                                    dataloaders['valid_image_paths'], \n",
    "                                                                    dataloaders['valid_labels'], \n",
    "                                                                    train_transforms=dataloaders['transforms'], \n",
    "                                                                    batch_size = self.batch_size,\n",
    "                                                                    shuffle=parameter['shuffle'],\n",
    "                                                                   sampler = dataloaders['sampler'])\n",
    "        self.class_names = parameter['class_names']\n",
    "        \n",
    "        self.activations_path = os.path.join('activations', self.name)\n",
    "        self.kernel_path = os.path.join('kernel_viz', self.name)\n",
    "        save_path = os.path.join(os.getcwd(), 'models', self.name)\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        if not os.path.exists(self.activations_path):\n",
    "            os.makedirs(self.activations_path)\n",
    "\n",
    "        if not os.path.exists(self.kernel_path):\n",
    "            os.makedirs(self.kernel_path)\n",
    "            \n",
    "        self.save_path = save_path\n",
    "\n",
    "    def train(self, save=True):\n",
    "        '''\n",
    "        @epochs: number of epochs to train\n",
    "        @save: whether or not to save the checkpoints\n",
    "        '''\n",
    "        best_val_accuracy = - math.inf\n",
    "        \n",
    "        for epoch in range(self.epoch):  # loop over the dataset multiple times\n",
    "            self.model.train()\n",
    "            t = time.time()\n",
    "            running_loss = 0.0\n",
    "            train_acc = 0\n",
    "            val_accuracy = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            count = 0\n",
    "            loop = tqdm.tqdm(self.train_loader, total = len(self.train_loader), leave = True)\n",
    "            \n",
    "            for img, label in loop:\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = img.to(device), label.to(device) #img.to(device), label.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = self.model(inputs)\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                total += labels.shape[0]\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                \n",
    "                count += 1\n",
    "                if count % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                    print(f'[{epoch + 1}, {count + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                    running_loss = 0.0\n",
    "                    \n",
    "            train_acc = 100 * correct / total\n",
    "            print(f'Epoch:', epoch + 1, f'Training Epoch Accuracy:{train_acc}')\n",
    "            \n",
    "            # evaluate the validation dataset\n",
    "            self.model.eval()\n",
    "            correct_pred = {classname: 0 for classname in self.class_names}\n",
    "            total_pred = {classname: 0 for classname in self.class_names}\n",
    "\n",
    "            # again no gradients needed\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data in self.valid_loader:\n",
    "                    images, labels = data[0].to(device), data[1].to(device) #data[0], data[1]\n",
    "                    outputs = self.model(images)\n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    # collect the correct predictions for each class\n",
    "                    total += labels.shape[0]\n",
    "                    correct += (predictions == labels).sum().item()\n",
    "\n",
    "                    for label, prediction in zip(labels, predictions):\n",
    "                        if label == prediction:\n",
    "                            correct_pred[classes[label]] += 1\n",
    "                        total_pred[classes[label]] += 1\n",
    "\n",
    "            val_accuracy = 100 * correct / total\n",
    "            print(f'Epoch:', epoch + 1, f'Validation Epoch Accuracy:{val_accuracy}')\n",
    "                        \n",
    "            # print the summary for each class\n",
    "            print('Epoch:', epoch + 1, 'Correct predictions', correct_pred)\n",
    "            print('Epoch:', epoch + 1, 'Total predictions', total_pred)\n",
    "            print('Epoch:', epoch + 1, 'Correct predictions', correct_pred)\n",
    "            print('Epoch:', epoch + 1, 'Total predictions', total_pred)\n",
    "            \n",
    "            # inspect the time taken to train one epoch\n",
    "            d = time.time()-t\n",
    "            print('Fininsh Trainig Epoch', epoch, '!', 'Time used:', d)\n",
    "            \n",
    "            if save:\n",
    "                torch.save(self.model.state_dict(), os.path.join(self.save_path, f'epoch_{epoch}.pt'))\n",
    "                if val_accuracy > best_val_accuracy:\n",
    "                    torch.save(self.model.state_dict(), os.path.join(self.save_path, 'best.pt'))\n",
    "                    best_val_accuracy = val_accuracy\n",
    "\n",
    "        print('Done training!')                       \n",
    "\n",
    "    \n",
    "    def evaluate(self):\n",
    "        # for evaluating the test dataset if there were any.\n",
    "        try:\n",
    "            assert os.path.exists(os.path.join(self.save_path, 'best.pt'))\n",
    "            \n",
    "        except:\n",
    "            print('Please train first')\n",
    "            return\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(os.path.join(self.save_path, 'best.pt')))\n",
    "        self.model.eval()\n",
    "        \n",
    "    def get_dataloaders(self, train_image_paths, train_labels, valid_image_paths, valid_labels, train_transforms=False, batch_size=32, shuffle=True, sampler = None):\n",
    "        train_dataset = SurgicalDataset(train_image_paths,train_labels, train_transforms)\n",
    "        val_dataset = SurgicalDataset(valid_image_paths,valid_labels, train_transforms)\n",
    "        train_loader = DataLoader(train_dataset, batch_size, shuffle, sampler)\n",
    "        valid_loader = DataLoader(val_dataset, batch_size, shuffle = True)\n",
    "        return train_loader, valid_loader\n",
    "    \n",
    "    def grad_cam_on_input(self, img):\n",
    "        \n",
    "        try:\n",
    "            assert os.path.exists(os.path.join(self.save_path, 'best.pt'))\n",
    "\n",
    "        except:\n",
    "            print('It appears you are testing the model without training. Please train first')\n",
    "            return\n",
    "\n",
    "        self.model.load_state_dict(torch.load(os.path.join(self.save_path, 'best.pt')))\n",
    "\n",
    "\n",
    "        self.model.eval()\n",
    "        img = img.to('cuda' if self.use_cuda else 'cpu')\n",
    "\n",
    "\n",
    "        out = self.model(img)\n",
    "\n",
    "        _, pred = torch.max(out, 1)\n",
    "\n",
    "        predicted_class = self.class_names[int(pred)]\n",
    "        print(f'Predicted class was {predicted_class}')\n",
    "\n",
    "        out[:, pred].backward()\n",
    "        gradients = self.model.get_gradient_activations()\n",
    "\n",
    "        print('Gradients shape: ', f'{gradients.shape}')\n",
    "\n",
    "        mean_gradients = torch.mean(gradients, [0, 2, 3]).cpu()\n",
    "        activations = self.model.get_final_conv_layer(img).detach().cpu()\n",
    "\n",
    "        print('Activations shape: ', f'{activations.shape}')\n",
    "\n",
    "        for idx in range(activations.shape[1]):\n",
    "            activations[:, idx, :, :] *= mean_gradients[idx]\n",
    "\n",
    "        final_heatmap = np.maximum(torch.mean(activations, dim=1).squeeze(), 0)\n",
    "\n",
    "        final_heatmap /= torch.max(final_heatmap)\n",
    "\n",
    "        return final_heatmap\n",
    "\n",
    "    def trained_kernel_viz(self):\n",
    "        \n",
    "        all_layers = [0, 3]\n",
    "        all_filters = []\n",
    "        for layer in all_layers:\n",
    "\n",
    "            filters = self.model.conv_model[layer].weight\n",
    "            all_filters.append(filters.detach().cpu().clone()[:8, :8, :, :])\n",
    "\n",
    "        for filter_idx in range(len(all_filters)):\n",
    "\n",
    "            filter = all_filters[filter_idx]\n",
    "            print(filter.shape)\n",
    "            filter = filter.contiguous().view(-1, 1, filter.shape[2], filter.shape[3])\n",
    "            image = show_img(make_grid(filter))\n",
    "            image = 255 * image\n",
    "            cv2.imwrite(os.path.join(self.kernel_path, f'filter_layer{all_layers[filter_idx]}.jpg'), image)\n",
    "    \n",
    "\n",
    "    def activations_on_input(self, img):\n",
    "        \n",
    "        img = img.to('cuda' if self.use_cuda else 'cpu')\n",
    "\n",
    "        all_layers = [0,3,6,8,10]\n",
    "        all_viz = []\n",
    "        \n",
    "        # looking at the outputs of the relu\n",
    "        for each in all_layers:\n",
    "\n",
    "            current_model = self.model.conv_model[:each+1]\n",
    "            current_out = current_model(img)\n",
    "            all_viz.append(current_out.detach().cpu().clone()[:, :64, :, :])\n",
    "\n",
    "        for viz_idx in range(len(all_viz)):\n",
    "\n",
    "            viz = all_viz[viz_idx]\n",
    "            viz = viz.view(-1, 1, viz.shape[2], viz.shape[3])\n",
    "            image = show_img(make_grid(viz))\n",
    "            image = 255 * image\n",
    "            cv2.imwrite(os.path.join(self.activations_path, f'sample_layer{all_layers[viz_idx]}.jpg'), image)    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f48099",
   "metadata": {},
   "source": [
    "# Build and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18d59f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet(\n",
      "  (features): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (2): ConvNormActivation(\n",
      "            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "            (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (2): ConvNormActivation(\n",
      "            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0036363636363636364, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "            (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (2): ConvNormActivation(\n",
      "            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.007272727272727273, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "            (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (2): ConvNormActivation(\n",
      "            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.01090909090909091, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "            (1): BatchNorm2d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.014545454545454545, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.01818181818181818, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.02181818181818182, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.025454545454545455, mode=row)\n",
      "      )\n",
      "      (4): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.02909090909090909, mode=row)\n",
      "      )\n",
      "      (5): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.03272727272727273, mode=row)\n",
      "      )\n",
      "      (6): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.03636363636363636, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(288, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.04, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.04363636363636364, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.04727272727272727, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.05090909090909091, mode=row)\n",
      "      )\n",
      "      (4): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.05454545454545454, mode=row)\n",
      "      )\n",
      "      (5): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.05818181818181818, mode=row)\n",
      "      )\n",
      "      (6): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.06181818181818183, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.06545454545454546, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.06909090909090909, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07272727272727272, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07636363636363637, mode=row)\n",
      "      )\n",
      "      (4): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08, mode=row)\n",
      "      )\n",
      "      (5): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08363636363636365, mode=row)\n",
      "      )\n",
      "      (6): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08727272727272728, mode=row)\n",
      "      )\n",
      "      (7): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.09090909090909091, mode=row)\n",
      "      )\n",
      "      (8): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.09454545454545454, mode=row)\n",
      "      )\n",
      "      (9): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.09818181818181819, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(960, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.10181818181818182, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.10545454545454547, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.10909090909090909, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.11272727272727273, mode=row)\n",
      "      )\n",
      "      (4): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.11636363636363636, mode=row)\n",
      "      )\n",
      "      (5): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.12000000000000001, mode=row)\n",
      "      )\n",
      "      (6): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.12363636363636366, mode=row)\n",
      "      )\n",
      "      (7): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.12727272727272726, mode=row)\n",
      "      )\n",
      "      (8): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.13090909090909092, mode=row)\n",
      "      )\n",
      "      (9): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.13454545454545455, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=1344, bias=False)\n",
      "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.13818181818181818, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.14181818181818184, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.14545454545454545, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1490909090909091, mode=row)\n",
      "      )\n",
      "      (4): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.15272727272727274, mode=row)\n",
      "      )\n",
      "      (5): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.15636363636363634, mode=row)\n",
      "      )\n",
      "      (6): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.16, mode=row)\n",
      "      )\n",
      "      (7): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.16363636363636364, mode=row)\n",
      "      )\n",
      "      (8): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1672727272727273, mode=row)\n",
      "      )\n",
      "      (9): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.17090909090909093, mode=row)\n",
      "      )\n",
      "      (10): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.17454545454545456, mode=row)\n",
      "      )\n",
      "      (11): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1781818181818182, mode=row)\n",
      "      )\n",
      "      (12): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.18181818181818182, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(640, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.18545454545454548, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
      "            (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(640, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1890909090909091, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
      "            (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(640, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.19272727272727275, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
      "            (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(640, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.19636363636363638, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (8): ConvNormActivation(\n",
      "      (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(2560, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=True)\n",
      "    (1): Linear(in_features=2560, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "example_model = models.efficientnet_b7(pretrained=True)\n",
    "print(example_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e782c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.5, inplace=True)\n",
      "  (1): Linear(in_features=2560, out_features=1000, bias=True)\n",
      ")\n",
      "AdaptiveAvgPool2d(output_size=1)\n"
     ]
    }
   ],
   "source": [
    "print(example_model.classifier)\n",
    "print(example_model.avgpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc689401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for name, param in example_model.named_parameters():\n",
    "    number = name.split('.')\n",
    "    print(number[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0610f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferEffiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base_effi_net = models.efficientnet_b7(pretrained=True)\n",
    "        self.conv_model = self.get_conv_layers()\n",
    "        self.avg_pool = self.transition_layer()\n",
    "        self.fc_model = self.get_fc_layers()\n",
    "        self.activate_training_layers()\n",
    "\n",
    "    def activate_training_layers(self):\n",
    "        for name, param in self.conv_model.named_parameters():\n",
    "            number = int(name.split('.')[1])\n",
    "            # for all layers except the last conv layer, set param.requires_grad = False\n",
    "            if number == 8:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        for name, param in self.fc_model.named_parameters():\n",
    "            # for all of these layers set param.requires_grad as True\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def get_conv_layers(self):\n",
    "        return self.base_effi_net.features\n",
    "\n",
    "    def transition_layer(self):\n",
    "        return self.base_effi_net.avgpool\n",
    "\n",
    "    def get_fc_layers(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=2560, out_features=1024, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=1024, out_features=512, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=15, bias=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_model(x)   #call the conv layers\n",
    "        x = self.avg_pool(x)  #call the avg pool layer\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc_model(x)  #call fully connected layers  \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ca39091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████▌                                                          | 1999/5377 [17:11<28:39,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▏                       | 3999/5377 [34:22<11:52,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  4000] loss: 0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5377/5377 [46:36<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training Epoch Accuracy:83.29390566421576\n",
      "Epoch: 1 Validation Epoch Accuracy:86.16200130196225\n",
      "Epoch: 1 Correct predictions {0: 49, 1: 2025, 2: 5246, 3: 9179, 4: 202, 5: 5030, 6: 138, 7: 2424, 8: 240, 9: 571, 10: 9576, 11: 1681, 12: 399, 13: 283, 14: 17}\n",
      "Epoch: 1 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 1 Correct predictions {0: 49, 1: 2025, 2: 5246, 3: 9179, 4: 202, 5: 5030, 6: 138, 7: 2424, 8: 240, 9: 571, 10: 9576, 11: 1681, 12: 399, 13: 283, 14: 17}\n",
      "Epoch: 1 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 0 ! Time used: 3368.0900659561157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████▌                                                          | 1999/5377 [17:11<28:46,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  2000] loss: 0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▏                       | 3999/5377 [34:20<12:31,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  4000] loss: 0.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5377/5377 [46:30<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Training Epoch Accuracy:90.04155889447529\n",
      "Epoch: 2 Validation Epoch Accuracy:90.14461080628662\n",
      "Epoch: 2 Correct predictions {0: 50, 1: 2080, 2: 5460, 3: 9345, 4: 199, 5: 5045, 6: 145, 7: 2218, 8: 244, 9: 566, 10: 10423, 11: 2296, 12: 402, 13: 283, 14: 17}\n",
      "Epoch: 2 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 2 Correct predictions {0: 50, 1: 2080, 2: 5460, 3: 9345, 4: 199, 5: 5045, 6: 145, 7: 2218, 8: 244, 9: 566, 10: 10423, 11: 2296, 12: 402, 13: 283, 14: 17}\n",
      "Epoch: 2 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 1 ! Time used: 3313.028431892395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████▌                                                          | 1999/5377 [17:01<28:19,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  2000] loss: 0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▏                       | 3999/5377 [34:05<12:16,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  4000] loss: 0.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5377/5377 [45:45<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Training Epoch Accuracy:91.81144468017088\n",
      "Epoch: 3 Validation Epoch Accuracy:92.74621035989956\n",
      "Epoch: 3 Correct predictions {0: 50, 1: 2117, 2: 5311, 3: 10037, 4: 184, 5: 5208, 6: 148, 7: 2248, 8: 242, 9: 564, 10: 10712, 11: 2369, 12: 403, 13: 282, 14: 17}\n",
      "Epoch: 3 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 3 Correct predictions {0: 50, 1: 2117, 2: 5311, 3: 10037, 4: 184, 5: 5208, 6: 148, 7: 2248, 8: 242, 9: 564, 10: 10712, 11: 2369, 12: 403, 13: 282, 14: 17}\n",
      "Epoch: 3 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 2 ! Time used: 3265.0815002918243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████▌                                                          | 1999/5377 [17:31<31:13,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  2000] loss: 0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▏                       | 3999/5377 [34:42<11:39,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  4000] loss: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5377/5377 [46:37<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Training Epoch Accuracy:92.8972071260426\n",
      "Epoch: 4 Validation Epoch Accuracy:93.10424997675068\n",
      "Epoch: 4 Correct predictions {0: 52, 1: 2084, 2: 5570, 3: 10066, 4: 190, 5: 5264, 6: 143, 7: 2545, 8: 245, 9: 564, 10: 10399, 11: 2222, 12: 402, 13: 283, 14: 17}\n",
      "Epoch: 4 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 4 Correct predictions {0: 52, 1: 2084, 2: 5570, 3: 10066, 4: 190, 5: 5264, 6: 143, 7: 2545, 8: 245, 9: 564, 10: 10399, 11: 2222, 12: 402, 13: 283, 14: 17}\n",
      "Epoch: 4 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 3 ! Time used: 3321.810596704483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████▌                                                          | 1999/5377 [17:06<28:45,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  2000] loss: 0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▏                       | 3999/5377 [34:22<11:45,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  4000] loss: 0.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5377/5377 [46:15<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Training Epoch Accuracy:93.82719637304194\n",
      "Epoch: 5 Validation Epoch Accuracy:94.00399888403237\n",
      "Epoch: 5 Correct predictions {0: 51, 1: 2094, 2: 5631, 3: 9911, 4: 176, 5: 5285, 6: 145, 7: 2457, 8: 245, 9: 567, 10: 10674, 11: 2494, 12: 400, 13: 286, 14: 17}\n",
      "Epoch: 5 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Epoch: 5 Correct predictions {0: 51, 1: 2094, 2: 5631, 3: 9911, 4: 176, 5: 5285, 6: 145, 7: 2457, 8: 245, 9: 567, 10: 10674, 11: 2494, 12: 400, 13: 286, 14: 17}\n",
      "Epoch: 5 Total predictions {0: 52, 1: 2177, 2: 5799, 3: 10405, 4: 213, 5: 5470, 6: 158, 7: 2843, 8: 247, 9: 587, 10: 11135, 11: 3216, 12: 404, 13: 288, 14: 18}\n",
      "Fininsh Trainig Epoch 4 ! Time used: 3302.5145978927612\n",
      "Done training!\n"
     ]
    }
   ],
   "source": [
    "# Train a transfer learning model with Alexnet\n",
    "name = 'TransferEffiNet'\n",
    "classes = [i for i in range(15)]\n",
    "transforms = get_transform('effinet')\n",
    "dataloaders = {'train_image_paths': train_image_paths, 'train_labels' : train_labels, 'valid_image_paths': valid_image_paths, 'valid_labels':valid_labels, 'transforms':transforms, 'sampler':sampler}\n",
    "parameters = {'lr': 0.001, 'epochs' : 5, 'batch_size':32, 'shuffle':False, 'class_names':classes}\n",
    "\n",
    "model = TransferEffiNet()\n",
    "classifier = Classifier(name, model, dataloaders, parameters, use_cuda=True)\n",
    "classifier.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1f0c3a",
   "metadata": {},
   "source": [
    "# Data Augmentations for scarse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98e75732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out the ratio of different labels/data\n",
    "\n",
    "# we decide to augment the scarser data in the following scheme: label 0, + 400, label 14 + 500, label 6 + 200\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
